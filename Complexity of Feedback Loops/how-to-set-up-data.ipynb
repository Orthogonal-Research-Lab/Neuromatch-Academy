{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "PsyTrack_Manuscript_Figures.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVzwz9MUgfbi",
        "colab_type": "text"
      },
      "source": [
        "# _Extracting the Dynamics of Behavior in Decision-Making Experiments_\n",
        "## Figure Generator\n",
        "\n",
        "by Nicholas A. Roy $\\quad$  _(v1.0, last updated May 21, 2020)_\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ats61fugfbk",
        "colab_type": "text"
      },
      "source": [
        "This notebook will precisely recreate all figures (Figures 1-9 and Supplementary Figures S1-4) from our manuscript _Extracting the Dynamics of Behavior in Decision-Making Experiments_. All figures will require the `PsyTrack` python package, as well as several other standard Python libraries. Figures requiring data will require that the corresponding dataset be downloaded and pre-processed. The necessary requirements for each figure are listed below, followed by instructions for downloading & preparing each of the three datasets:\n",
        " \n",
        " - Only the `PsyTrack` package is needed to produce the simulated data required for Figures 1, 2, and S1\n",
        " \n",
        " - The IBL mouse dataset is required (as well as the `ONE Light` Python library) for Figures 3, 4, S2, and S3\n",
        " \n",
        " - The Akrami rat dataset is required for Figures 5, 6, and 8\n",
        " \n",
        " - The Akrami human subject dataset is required for Figures 7 and S4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PC-AFFuugfbl",
        "colab_type": "text"
      },
      "source": [
        "A section with preliminary setup code is below, followed by code and instructions to load each dataset. There is then a section for each figure, with subsections for each subfigure. A few things to note:\n",
        "\n",
        " - **ALTERATIONS** | Many subfigures in the paper include some superficial additions done in Adobe Illustrator. Subfigures created purely inside Adobe illustrator (e.g. schematic figures) are noted.\n",
        " - **COMPUTE TIME** | While most individual `PsyTrack` models can be fit quickly, some figure require fitting dozens of models and so can take a relatively long time to compute. Subfigures which take longer than 90 seconds to produce are marked with an approximation of how long they ought to take.\n",
        " - **LOCAL STORAGE** | Many figures save the results of model fits to local storage, so figures can be retrieved and modified without having to refit the model each time. All the temporary files produced by the notebook are saved to the directory specified by the `SPATH` variable in the Preliminary setup section below. All temporary files plus all the subfigures saved should use under 500MB total. Note that if you are using a Colab hosted runtime, then anything saved to Colab local storage will disappear once the runtime expires (Colab has a 12 hour max). There is code to download all figures from Colab at the end of the notebook.\n",
        " - **SUBFIGURE DEPENDENCIES** | Occasionally, subfigures will depend upon the results of an earlier subfigure (usually part of the same figure) — a cell which fails to run may simply need an earlier cell to be run first (these instances should be clearly marked).\n",
        " - **SUBJECT-SPECIFIC DETAILS** | Many analyses run on an example subject should allow for other subjects to be easily swapped in, but some analyses may have subject-specific code that may impede this (i.e. hardcoded dates to extract certain sessions for analysis).\n",
        " - **VERSIONING** | Any additions, fixes, or changes made to this notebook will be noted in the versioning section at the very end of the notebook.\n",
        " \n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoDseNg1gfbl",
        "colab_type": "text"
      },
      "source": [
        "# Preliminary setup and data retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGBQ_oIugfbm",
        "colab_type": "text"
      },
      "source": [
        "Users will need to install the `PsyTrack` package (version 1.3), by running the cell below. We also define a variable `SPATH` which is the directory where all data files and figures produced by the notebook will be saved.\n",
        "\n",
        "Several standard Python packages are used: `numpy`, `scipy`, `matplotlib`, and `pandas`. We import all these libraries before proceeding, as well as setting several parameters in `matplotlib` to standardize the figures produced."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-23T10:04:43.698269Z",
          "start_time": "2020-04-23T10:04:40.446048Z"
        },
        "id": "QSa5tS2Ngfbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Install then import PsyTrack\n",
        "!pip install psytrack==1.3\n",
        "import psytrack as psy\n",
        "\n",
        "# Set save path for all figures, decide whether to save permanently\n",
        "SPATH = \"ColabFigureData/\"\n",
        "!mkdir -p \"{SPATH}\"\n",
        "\n",
        "# Set matplotlib defaults for making files consistent in Illustrator\n",
        "colors = psy.COLORS\n",
        "zorder = psy.ZORDER\n",
        "plt.rcParams['figure.dpi'] = 140\n",
        "plt.rcParams['savefig.dpi'] = 300\n",
        "plt.rcParams['savefig.facecolor'] = (1,1,1,0)\n",
        "plt.rcParams['savefig.bbox'] = \"tight\"\n",
        "plt.rcParams['font.size'] = 10\n",
        "# plt.rcParams['font.family'] = 'sans-serif'     # not available in Colab\n",
        "# plt.rcParams['font.sans-serif'] = 'Helvetica'  # not available in Colab\n",
        "plt.rcParams['pdf.fonttype'] = 42\n",
        "plt.rcParams['xtick.labelsize'] = 10\n",
        "plt.rcParams['ytick.labelsize'] = 10\n",
        "plt.rcParams['axes.labelsize'] = 12\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FqDWGYngfbs",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VB3VveZugfbs",
        "colab_type": "text"
      },
      "source": [
        "## Download and pre-process IBL mouse data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWmLrfQAgfbt",
        "colab_type": "text"
      },
      "source": [
        "1) Use the command below to instal the IBL's [ONE Light](https://github.com/int-brain-lab/ibllib/tree/master/oneibl) Python library, download the [IBL mouse behavior dataset](https://doi.org/10.6084/m9.figshare.11636748.v7) _(version 7, uploaded February 7, 2020)_ to our `SPATH` directory as `ibl-behavior-data-Dec2019.zip`, and unzip the file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:17:34.515838Z",
          "start_time": "2020-04-18T01:17:34.476422Z"
        },
        "id": "SomAMEKhgfbu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install ibllib\n",
        "!wget -nc -O \"{SPATH}ibl-behavior-data-Dec2019.zip\" \"https://ndownloader.figshare.com/files/21623715\"\n",
        "!unzip -d \"{SPATH}\" -n \"{SPATH}ibl-behavior-data-Dec2019.zip\"\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mqj3mF1sgfbx",
        "colab_type": "text"
      },
      "source": [
        "2) Use the [ONE Light](https://github.com/int-brain-lab/ibllib/tree/master/oneibl) library to build a table of all the subject and session data contained within the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:18:08.044366Z",
          "start_time": "2020-04-18T01:17:36.492208Z"
        },
        "scrolled": false,
        "id": "eoXYyz62gfby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from oneibl.onelight import ONE\n",
        "\n",
        "ibl_data_path = SPATH + 'ibl-behavioral-data-Dec2019'\n",
        "current_cwd = os.getcwd()\n",
        "os.chdir(ibl_data_path)\n",
        "\n",
        "# Search all sessions that have these dataset types.\n",
        "required_vars = ['_ibl_trials.choice', '_ibl_trials.contrastLeft',\n",
        "                 '_ibl_trials.contrastRight','_ibl_trials.feedbackType']\n",
        "one = ONE()\n",
        "eids = one.search(required_vars)\n",
        "\n",
        "mouseData = pd.DataFrame()\n",
        "for eid in eids:\n",
        "    lab, _, subject, date, session = eid.split(\"/\")    \n",
        "    sess_vars = {\n",
        "        \"eid\": eid,\n",
        "        \"lab\": lab,\n",
        "        \"subject\": subject,\n",
        "        \"date\": date,\n",
        "        \"session\": session,\n",
        "    }\n",
        "    mouseData = mouseData.append(sess_vars, sort=True, ignore_index=True)\n",
        "\n",
        "os.chdir(current_cwd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDOOSP3ggfb4",
        "colab_type": "text"
      },
      "source": [
        "3) Next, we use the table of session data to process the raw trial data below into a single CSV file, `ibl_processed.csv`, saved to our `SPATH` directory.\n",
        "\n",
        "There are several known anomalies in the raw data:\n",
        " - CSHL_002 codes left contrasts as negative right contrasts on 81 trials (these trials are corrected)\n",
        " - ZM_1084 has `feedbackType` of 0 for 3 trials (these trials are omitted)\n",
        " - DY_009, DY_010, DY_011 each have <5000 trials total (no adjustment)\n",
        " - ZM_1367, ZM_1369, ZM_1371, ZM_1372, and ZM_1743 are shown non-standard contrast values of 0.04 and 0.08 (no adjustment)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:19:44.870215Z",
          "start_time": "2020-04-18T01:18:08.047871Z"
        },
        "id": "xZVDIrTkgfb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_vars = [\"contrastLeft\", \"contrastRight\", \"choice\", \"feedbackType\", \"probabilityLeft\"]\n",
        "df = pd.DataFrame()\n",
        "\n",
        "all_mice = []\n",
        "for j, s in enumerate(mouseData[\"subject\"].unique()):\n",
        "    print(\"\\rProcessing \" + str(j+1) + \" of \" + str(len(mouseData[\"subject\"].unique())), end=\"\")\n",
        "    mouse = mouseData[mouseData[\"subject\"]==s].sort_values(['date', 'session']).reset_index()\n",
        "    for i, row in mouse.iterrows():\n",
        "        myVars = {}\n",
        "        for v in all_vars:\n",
        "            filename = \"_ibl_trials.\" + v + \".npy\"\n",
        "            var_file = os.path.join(ibl_data_path, row.eid, \"alf\", filename)\n",
        "            myVars[v] = list(np.load(var_file).flatten())\n",
        "\n",
        "        num_trials = len(myVars[v])\n",
        "        myVars['lab'] = [row.lab]*num_trials\n",
        "        myVars['subject'] = [row.subject]*num_trials\n",
        "        myVars['date'] = [row.date]*num_trials\n",
        "        myVars['session'] = [row.session]*num_trials\n",
        "\n",
        "        all_mice += [pd.DataFrame(myVars, columns=myVars.keys())]\n",
        "        \n",
        "df = pd.concat(all_mice, ignore_index=True)\n",
        "\n",
        "df = df[df['choice'] != 0]        # dump mistrials\n",
        "df = df[df['feedbackType'] != 0]  # 3 anomalous trials from ZM_1084, omit\n",
        "df.loc[np.isnan(df['contrastLeft']), \"contrastLeft\"] = 0\n",
        "df.loc[np.isnan(df['contrastRight']), \"contrastRight\"] = 0\n",
        "df.loc[df[\"contrastRight\"] < 0, \"contrastLeft\"] = np.abs(df.loc[df[\"contrastRight\"] < 0, \"contrastRight\"])\n",
        "df.loc[df[\"contrastRight\"] < 0, \"contrastRight\"] = 0  # 81 anomalous trials in CSHL_002, correct\n",
        "df[\"answer\"] = df[\"feedbackType\"] * df[\"choice\"]      # new column to indicate correct answer\n",
        "df.loc[df[\"answer\"]==1, \"answer\"] = 0\n",
        "df.loc[df[\"answer\"]==-1, \"answer\"] = 1\n",
        "df.loc[df[\"feedbackType\"]==-1, \"feedbackType\"] = 0\n",
        "df.loc[df[\"choice\"]==1, \"choice\"] = 0\n",
        "df.loc[df[\"choice\"]==-1, \"choice\"] = 1\n",
        "df.to_csv(SPATH+\"ibl_processed.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdDIQpC6gfb_",
        "colab_type": "text"
      },
      "source": [
        "4) Next we run a few sanity checks on our data, to make sure everything processed correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:19:45.504667Z",
          "start_time": "2020-04-18T01:19:44.873131Z"
        },
        "id": "UONTFii8gfb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"contrastLeft: \", np.unique(df['contrastLeft']))   # [0, 0.0625, 0.125, 0.25, 0.5, 1.0] and [0.04, 0.08]\n",
        "print(\"contrastRight: \", np.unique(df['contrastRight'])) # [0, 0.0625, 0.125, 0.25, 0.5, 1.0] and [0.04, 0.08]\n",
        "print(\"choice: \", np.unique(df['choice']))               # [0, 1]\n",
        "print(\"feedbackType: \", np.unique(df['feedbackType']))   # [0, 1]\n",
        "print(\"answer: \", np.unique(df['answer']))               # [0, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVDFZXBogfcE",
        "colab_type": "text"
      },
      "source": [
        "5) Finally, we define a function `getMouse` that extracts the data for a single mouse from our CSV file, and returns it as a PsyTrack compatible `dict`. We will use this function to access IBL mouse data in the figures below. Note the keyword argument and default value $p=5$ which controls the strength of the $\\tanh$ transformation on the contrast values. See Figure S3 and the STAR Methods of the accompanying paper for more details.\n",
        "\n",
        "**Note:** Once steps 1-5 have been run once, only step 5 will need to be run on subsequent uses."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:19:48.906769Z",
          "start_time": "2020-04-18T01:19:45.508884Z"
        },
        "id": "uC-l-HP_gfcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ibl_mouse_data_path = SPATH + \"ibl_processed.csv\"\n",
        "\n",
        "MOUSE_DF = pd.read_csv(ibl_mouse_data_path)\n",
        "def getMouse(subject, p=5):\n",
        "    df = MOUSE_DF[MOUSE_DF['subject']==subject]   # Restrict data to the subject specified\n",
        "    \n",
        "    cL = np.tanh(p*df['contrastLeft'])/np.tanh(p)   # tanh transformation of left contrasts\n",
        "    cR = np.tanh(p*df['contrastRight'])/np.tanh(p)  # tanh transformation of right contrasts\n",
        "    inputs = dict(cL = np.array(cL)[:, None], cR = np.array(cR)[:, None])\n",
        "\n",
        "    dat = dict(\n",
        "        subject=subject,\n",
        "        lab=np.unique(df[\"lab\"])[0],\n",
        "        contrastLeft=np.array(df['contrastLeft']),\n",
        "        contrastRight=np.array(df['contrastRight']),\n",
        "        date=np.array(df['date']),\n",
        "        dayLength=np.array(df.groupby(['date','session']).size()),\n",
        "        correct=np.array(df['feedbackType']),\n",
        "        answer=np.array(df['answer']),\n",
        "        probL=np.array(df['probabilityLeft']),\n",
        "        inputs = inputs,\n",
        "        y = np.array(df['choice'])\n",
        "    )\n",
        "    \n",
        "    return dat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oi6Sc1n8gfcJ",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goNXR7VYgfcJ",
        "colab_type": "text"
      },
      "source": [
        "## Download and pre-process Akrami rat data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9-mLFgzgfcK",
        "colab_type": "text"
      },
      "source": [
        "1) Download the [Akrami rat behavior dataset](https://doi.org/10.6084/m9.figshare.12213671.v1) _(version 1, uploaded May 18, 2020)_ to the `SPATH` directory as `rat_behavior.csv`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPm05P0JslVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -nc -O \"{SPATH}rat_behavior.csv\" \"https://ndownloader.figshare.com/files/22461707\"\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2u1GvUL1jjp",
        "colab_type": "text"
      },
      "source": [
        "2) Sessions in the data corresponding to early shaping stages will be omitted, as will all mistrials (see the dataset's README for more info). The `getRat` function will then load a particular rat into a PsyTrack compatible `dict`.\n",
        "\n",
        "`getRat` has two optional parameters: `first` which will return a data set with only the first `first` trials (the default of 20,000 works for all analyses); `cutoff` excludes sessions with fewer than `cutoff` valid trials (default set to 50). We will use this function to access Akrami rat data in the figures below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:19:58.436964Z",
          "start_time": "2020-04-18T01:19:56.236185Z"
        },
        "id": "kcbHUY2tgfcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "akrami_rat_data_path = SPATH + \"rat_behavior.csv\"\n",
        "\n",
        "RAT_DF = pd.read_csv(akrami_rat_data_path)\n",
        "RAT_DF = RAT_DF[RAT_DF[\"training_stage\"] > 2]  # Remove trials from early training\n",
        "RAT_DF = RAT_DF[~np.isnan(RAT_DF[\"choice\"])]   # Remove mistrials\n",
        "def getRat(subject, first=20000, cutoff=50):\n",
        "\n",
        "    df = RAT_DF[RAT_DF['subject_id']==subject]  # restrict dataset to single subject\n",
        "    df = df[:first]  # restrict to \"first\" trials of data\n",
        "    # remove sessions with fewer than \"cutoff\" valid trials\n",
        "    df = df.groupby('session').filter(lambda x: len(x) >= cutoff)   \n",
        "\n",
        "    # Normalize the stimuli to standard normal\n",
        "    s_a = (df[\"s_a\"] - np.mean(df[\"s_a\"]))/np.std(df[\"s_a\"])\n",
        "    s_b = (df[\"s_b\"] - np.mean(df[\"s_b\"]))/np.std(df[\"s_b\"])\n",
        "    \n",
        "    # Determine which trials do not have a valid previous trial (mistrial or session boundary)\n",
        "    t = np.array(df[\"trial\"])\n",
        "    prior = ((t[1:] - t[:-1]) == 1).astype(int)\n",
        "    prior = np.hstack(([0], prior))\n",
        "\n",
        "    # Calculate previous average tone value\n",
        "    s_avg = (df[\"s_a\"][:-1] + df[\"s_b\"][:-1])/2\n",
        "    s_avg = (s_avg - np.mean(s_avg))/np.std(s_avg)\n",
        "    s_avg = np.hstack(([0], s_avg))\n",
        "    s_avg = s_avg * prior  # for trials without a valid previous trial, set to 0\n",
        "\n",
        "    # Calculate previous correct answer\n",
        "    h = (df[\"correct_side\"][:-1] * 2 - 1).astype(int)   # map from (0,1) to (-1,1)\n",
        "    h = np.hstack(([0], h))\n",
        "    h = h * prior  # for trials without a valid previous trial, set to 0\n",
        "    \n",
        "    # Calculate previous choice\n",
        "    c = (df[\"choice\"][:-1] * 2 - 1).astype(int)   # map from (0,1) to (-1,1)\n",
        "    c = np.hstack(([0], c))\n",
        "    c = c * prior  # for trials without a valid previous trial, set to 0\n",
        "    \n",
        "    inputs = dict(s_a = np.array(s_a)[:, None],\n",
        "                  s_b = np.array(s_b)[:, None],\n",
        "                  s_avg = np.array(s_avg)[:, None],\n",
        "                  h = np.array(h)[:, None],\n",
        "                  c = np.array(c)[:, None])\n",
        "\n",
        "    dat = dict(\n",
        "        subject = subject,\n",
        "        inputs = inputs,\n",
        "        s_a = np.array(df['s_a']),\n",
        "        s_b = np.array(df['s_b']),\n",
        "        correct = np.array(df['hit']),\n",
        "        answer = np.array(df['correct_side']),\n",
        "        y = np.array(df['choice']),\n",
        "        dayLength=np.array(df.groupby(['session']).size()),\n",
        "    )\n",
        "    return dat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EI9GPcdLgfcq",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StmsyvQsgfcq",
        "colab_type": "text"
      },
      "source": [
        "## Download and pre-process Akrami human subject data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCDDDY5Vgfcr",
        "colab_type": "text"
      },
      "source": [
        "1) Download the [Akrami human subject behavior dataset](https://doi.org/10.6084/m9.figshare.12213671.v1) _(version 1, uploaded May 18, 2020)_. See the dataset's README for more info."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dO5rg5Rw262N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -nc -O \"{SPATH}human_auditory.csv\" \"https://ndownloader.figshare.com/files/22461695\"\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4KN65Oe279h",
        "colab_type": "text"
      },
      "source": [
        "2) We define a function `getHuman` that extracts the data for a single human subject from the downloaded CSV file, and returns it in a PsyTrack compatible `dict`. We will use this function to access Akrami human subject data in the figures below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:20:03.756258Z",
          "start_time": "2020-04-18T01:20:03.660818Z"
        },
        "id": "jXxcPbFkgfcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "akrami_human_data_path = SPATH + \"human_auditory.csv\"\n",
        "\n",
        "HUMAN_DF = pd.read_csv(akrami_human_data_path)\n",
        "def getHuman(subject):\n",
        "    \n",
        "    df = HUMAN_DF[HUMAN_DF['subject_id']==subject]\n",
        "    \n",
        "    s_a = (df[\"s_a\"] - np.mean(df[\"s_a\"]))/np.std(df[\"s_a\"])\n",
        "    s_b = (df[\"s_b\"] - np.mean(df[\"s_b\"]))/np.std(df[\"s_b\"])\n",
        "    \n",
        "    s_avg = (df[\"s_a\"][:-1] + df[\"s_b\"][:-1])/2\n",
        "    s_avg = (s_avg - np.mean(s_avg))/np.std(s_avg)\n",
        "    s_avg = np.hstack(([0], s_avg))\n",
        "    \n",
        "    inputs = dict(s_a = np.array(s_a)[:, None],\n",
        "                  s_b = np.array(s_b)[:, None],\n",
        "                  s_avg = np.array(s_avg)[:, None])\n",
        "\n",
        "    dat = dict(\n",
        "        subject = subject,\n",
        "        inputs = inputs,\n",
        "        s_a = np.array(df['s_a']),\n",
        "        s_b = np.array(df['s_b']),\n",
        "        correct = np.array(df['reward']),\n",
        "        answer = np.array(df['correct_side']),\n",
        "        y = np.array(df['choice'])\n",
        "    )\n",
        "    return dat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9nWJYRigfcu",
        "colab_type": "text"
      },
      "source": [
        "# Figure 1 | Schematic of Psychometric Weight Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xs7KBSawgfcv",
        "colab_type": "text"
      },
      "source": [
        "**(A)** IBL task schematic (Illustrator only)\n",
        "\n",
        "**(B)** Example inputs (Illustrator only)\n",
        "\n",
        "**(C)** Schematic weight trajectories using regressors in (B)\n",
        "\n",
        "**(D)** Psychometric curves produced from weights from (C) at different points in training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z49XZ7EIgfcv",
        "colab_type": "text"
      },
      "source": [
        "## Figure 1c"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:20:47.609533Z",
          "start_time": "2020-04-18T01:20:47.155907Z"
        },
        "id": "s-SYvwAfgfcw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fig 1b — generate schematic weight trajectories\n",
        "def sigmoid(lenx, bias, slope):\n",
        "    x = np.arange(lenx)\n",
        "    return 1.0/(1.0 + np.exp(-(x-bias)/slope))\n",
        "\n",
        "x = np.arange(10000)\n",
        "bias_w = 0.8*sigmoid(10000, 6000, 1500)[::-1] - 0.08\n",
        "sL_w = -sigmoid(10000, 5000, 700) + 0.05\n",
        "sR_w = sigmoid(10000, 6500, 800) - 0.1\n",
        "\n",
        "gain = 4\n",
        "w = gain*np.vstack((bias_w,sL_w,sR_w))\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(3.5,1.2))\n",
        "plt.plot(x, w[0], c=colors['bias'], lw=2)\n",
        "plt.plot(x, w[1], c=colors['sL'], lw=2)\n",
        "plt.plot(x, w[2], c=colors['sR'], lw=2)\n",
        "\n",
        "plt.axhline(0, color=\"black\", linestyle=\"--\", alpha=0.5, zorder=0)\n",
        "\n",
        "plt.xticks([]); plt.yticks([0])\n",
        "plt.gca().set_yticklabels([0])\n",
        "plt.xlim(0,10000); plt.ylim(-1.02*gain,1.02*gain)\n",
        "# plt.xlabel(\"Trials\"); plt.ylabel(\"Weights\")\n",
        "\n",
        "# hand pick divider lines to make the Illustrator plot look nice\n",
        "xs = [1270,4975,8690]\n",
        "for x in xs:\n",
        "    plt.axvline(x, color=\"gray\", lw=2, alpha=0.0)\n",
        "    \n",
        "plt.gca().spines['right'].set_visible(False)\n",
        "plt.gca().spines['top'].set_visible(False) \n",
        "\n",
        "# this makes the plot itself reflect the figsize, excluding the axis labels and ticks\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"Fig1c.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g86S8IL2gfcy",
        "colab_type": "text"
      },
      "source": [
        "## Figure 1d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:20:51.843072Z",
          "start_time": "2020-04-18T01:20:51.430171Z"
        },
        "id": "vLrHM1PHgfcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fig 1c — generate psychmoetric curves corresponding to weights at various times\n",
        "def generate_psych(w,x):\n",
        "    xL = x.copy(); xR = x.copy()\n",
        "    xL[xL>0] = 0; xR[xR<0] = 0\n",
        "    xL = np.abs(xL)\n",
        "    \n",
        "    wx = w[0] + xL*w[1] + xR*w[2]\n",
        "    pR = 1/(1+np.exp(-wx))\n",
        "    return pR\n",
        "\n",
        "# Generate psychometric curve for each time point in xs\n",
        "for i,cut in enumerate(xs):\n",
        "\n",
        "    x = np.arange(-1,1.01,.01)\n",
        "    pR = generate_psych(w[:,cut],x)\n",
        "    \n",
        "    x_dot = np.array([-1.0,-0.5,0.0,0.5,1.0])\n",
        "    pR_dot = generate_psych(w[:,cut],x_dot)\n",
        "\n",
        "    plt.figure(figsize=(1.25,1))\n",
        "    plt.plot(x*100, pR*100, color=\"black\", lw=1.5)\n",
        "    plt.plot(x_dot*100, pR_dot*100, color=\"black\", marker='o', lw=0, markersize=4)\n",
        "\n",
        "    # Grid lines\n",
        "    plt.axvline(  0, color=\"black\", linestyle=\"-\", alpha=0.1)\n",
        "    plt.axhline( 50, color=\"black\", linestyle=\"-\", alpha=0.1)\n",
        "    \n",
        "    plt.xticks([-100,-50,0,50,100]); plt.yticks([0,50,100])\n",
        "    plt.gca().set_xticklabels([]); plt.gca().set_yticklabels([])\n",
        "    plt.xlim(-110,110); plt.ylim(0,100)\n",
        "#     plt.xlabel(\"Right - Left Contrast (%)\"); plt.ylabel(\"Prob. Left (%)\")\n",
        "    \n",
        "    plt.gca().spines['right'].set_visible(False)\n",
        "    plt.gca().spines['top'].set_visible(False)\n",
        "\n",
        "    plt.savefig(SPATH + \"Fig1d_\"+str(i)+\".pdf\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQ-JO6xagfc2",
        "colab_type": "text"
      },
      "source": [
        "# Figure 2 | Recovering Psychometric Weights from Simulated Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rlz7aWNsgfc3",
        "colab_type": "text"
      },
      "source": [
        "**(A)** $K=4$ simulated weights of different sigma for $N=5000$ trials, with recovery showing 95% credible interval\n",
        "\n",
        "**(B)** Show the recovery for each sigma in (A), with 95% credible interval\n",
        "\n",
        "**(C)** 3 simulated weights as in (A), except with $\\sigma_{\\text{Day}}$  \n",
        "\n",
        "**(D)** Show the recovery for hyperparameters in (C), as in (B)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grMdVjPfgfc4",
        "colab_type": "text"
      },
      "source": [
        "## Figure 2a"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:21:23.652294Z",
          "start_time": "2020-04-18T01:21:23.599016Z"
        },
        "id": "9preesL9gfc4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fig 2a — generate simulated weights and recover with errorbars\n",
        "# Simulate\n",
        "seed = 31  # paper uses 31\n",
        "num_weights = 4\n",
        "num_trials = 5000\n",
        "hyper = {'sigma'   : 2**np.array([-4.0,-5.0,-6.0,-7.0]),\n",
        "         'sigInit' : 2**np.array([ 0.0, 0.0, 0.0, 0.0])}\n",
        "\n",
        "# Compute\n",
        "gen = psy.generateSim(K=num_weights, N=num_trials, hyper=hyper,\n",
        "                      boundary=6.0, iterations=1, seed=seed, savePath=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:22:20.042274Z",
          "start_time": "2020-04-18T01:21:24.430418Z"
        },
        "id": "9N2ywbjsgfc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Recovery\n",
        "rec = psy.recoverSim(gen)\n",
        "\n",
        "# Save interim result\n",
        "np.savez_compressed(SPATH+'fig2a_data.npz', rec=rec, gen=gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:22:20.955598Z",
          "start_time": "2020-04-18T01:22:20.045791Z"
        },
        "id": "Kz1SsURpgfdA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reload data\n",
        "rec = np.load(SPATH+'fig2a_data.npz', allow_pickle=True)['rec'].item()\n",
        "gen = np.load(SPATH+'fig2a_data.npz', allow_pickle=True)['gen'].item()\n",
        "\n",
        "# Plotting\n",
        "sim_colors = [colors['bias'], colors['s1'], colors['s2'], colors['s_avg']]\n",
        "fig = plt.figure(figsize=(3.75,1.4))\n",
        "for i, c in enumerate(sim_colors):\n",
        "    plt.plot(gen['W'][:,i], c=c, lw=0.5, zorder=2*i)\n",
        "    plt.plot(rec['wMode'][i], c=c, lw=1, linestyle='--', alpha=0.5, zorder=2*i+1)\n",
        "    plt.fill_between(np.arange(num_trials),\n",
        "                     rec['wMode'][i] - 2 * rec['hess_info']['W_std'][i],\n",
        "                     rec['wMode'][i] + 2 * rec['hess_info']['W_std'][i],\n",
        "                     facecolor=c, alpha=0.2, zorder=2*i+1)\n",
        "\n",
        "plt.axhline(0, color=\"black\", linestyle=\"--\", lw=0.5, alpha=0.5, zorder=0)\n",
        "\n",
        "plt.xticks(1000*np.arange(0,11))\n",
        "plt.gca().set_xticklabels([0,1000,2000,3000,4000,5000])\n",
        "plt.yticks(np.arange(-4,5,2))\n",
        "\n",
        "plt.xlim(0,5000); plt.ylim(-4.3,4.3)\n",
        "# plt.xlabel(\"Trials\"); plt.ylabel(\"Weights\")\n",
        "\n",
        "plt.gca().spines['right'].set_visible(False)\n",
        "plt.gca().spines['top'].set_visible(False)\n",
        "\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"Fig2a.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfheuyCbgfdC",
        "colab_type": "text"
      },
      "source": [
        "## Figure 2b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:22:22.107697Z",
          "start_time": "2020-04-18T01:22:20.958733Z"
        },
        "id": "37Xdf6p6gfdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reload data\n",
        "rec = np.load(SPATH+'fig2a_data.npz', allow_pickle=True)['rec'].item()\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(1.4,1.4))\n",
        "\n",
        "true_sigma = np.log2(rec['input']['sigma'])\n",
        "avg_sigma = np.log2(rec['hyp']['sigma'])\n",
        "err_sigma = rec['hess_info']['hyp_std']\n",
        "\n",
        "for i, c in enumerate(sim_colors):\n",
        "    plt.plot([i-0.3, i+0.3], [true_sigma[i]]*2, color=\"black\", linestyle=\"-\", lw=1.2, zorder=0)\n",
        "    plt.errorbar([i], avg_sigma[i], yerr=1.96*err_sigma[i], c=c, lw=1, marker='o', markersize=5)\n",
        "\n",
        "plt.xticks([0,1,2,3]); plt.yticks(np.arange(-8,-2))\n",
        "plt.xlim(-0.5,3.5); plt.ylim(-7.5,-3.5)\n",
        "\n",
        "plt.gca().set_xticklabels([r\"$\\sigma_1$\", r\"$\\sigma_2$\", r\"$\\sigma_3$\", r\"$\\sigma_4$\"])\n",
        "\n",
        "# plt.ylabel(r\"$\\log_2(\\sigma)$\")\n",
        "\n",
        "plt.gca().spines['right'].set_visible(False)\n",
        "plt.gca().spines['top'].set_visible(False)\n",
        "\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"Fig2b.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBkpetNAgfdG",
        "colab_type": "text"
      },
      "source": [
        "## Figure 2c\n",
        "\n",
        "_2 min_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:22:30.507549Z",
          "start_time": "2020-04-18T01:22:30.451982Z"
        },
        "id": "Ku9em5AEgfdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fig 2c — generate simulated weights and recover with errorbars\n",
        "# Simulate\n",
        "seed = 102  # paper uses 102\n",
        "num_weights = 3\n",
        "num_trials = 5000\n",
        "hyper = {'sigma'   : 2**np.array([-4.5, -5.0,-16.0]),\n",
        "         'sigInit' : 2**np.array([ 0.0,  0.0,  0.0]),\n",
        "         'sigDay'  : 2**np.array([ 0.5,-16.0,  1.0])\n",
        "        }\n",
        "days = [500]*9\n",
        "\n",
        "# Compute\n",
        "gen = psy.generateSim(K=num_weights, N=num_trials, hyper=hyper, days=days,\n",
        "                      boundary=10.0, iterations=1, seed=seed, savePath=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:24:04.446435Z",
          "start_time": "2020-04-18T01:22:31.149855Z"
        },
        "id": "6CKzejNOgfdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Recovery\n",
        "rec = psy.recoverSim(gen)\n",
        "\n",
        "# Save interim result\n",
        "np.savez_compressed(SPATH+'fig2c_data.npz', rec=rec, gen=gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:24:05.242522Z",
          "start_time": "2020-04-18T01:24:04.449465Z"
        },
        "id": "X5tkEDQSgfdL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reload data\n",
        "rec = np.load(SPATH+'fig2c_data.npz', allow_pickle=True)['rec'].item()\n",
        "gen = np.load(SPATH+'fig2c_data.npz', allow_pickle=True)['gen'].item()\n",
        "\n",
        "# Plotting\n",
        "sim_colors = [colors['bias'], colors['s1'], colors['s2']]\n",
        "fig = plt.figure(figsize=(3.75,1.4))\n",
        "for i, c in enumerate(sim_colors):\n",
        "    plt.plot(gen['W'][:,i], c=c, lw=0.5, zorder=5-i)\n",
        "    plt.plot(rec['wMode'][i], c=c, lw=1, linestyle='--', alpha=0.5, zorder=5-i)\n",
        "    plt.fill_between(np.arange(num_trials),\n",
        "                     rec['wMode'][i] - 2 * rec['hess_info']['W_std'][i],\n",
        "                     rec['wMode'][i] + 2 * rec['hess_info']['W_std'][i],\n",
        "                     facecolor=c, alpha=0.2, zorder=5-i)\n",
        "\n",
        "for i in np.cumsum(days):\n",
        "    plt.axvline(i, color=\"black\", lw=0.5, alpha=0.5, zorder=0)\n",
        "    \n",
        "plt.axhline(0, color=\"black\", linestyle=\"--\", lw=0.5, alpha=0.5, zorder=0)\n",
        "plt.xticks(1000*np.arange(0,11))\n",
        "plt.gca().set_xticklabels([0,1000,2000,3000,4000,5000])\n",
        "plt.yticks(np.arange(-4,5,2))\n",
        "\n",
        "plt.xlim(0,5000); plt.ylim(-4.3,4.3)\n",
        "# plt.xlabel(\"Trials\"); plt.ylabel(\"Weights\")\n",
        "\n",
        "plt.gca().spines['right'].set_visible(False)\n",
        "plt.gca().spines['top'].set_visible(False)\n",
        "\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"Fig2c.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7xT0AYogfdO",
        "colab_type": "text"
      },
      "source": [
        "## Figure 2d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:24:06.049780Z",
          "start_time": "2020-04-18T01:24:05.245499Z"
        },
        "id": "baroICDmgfdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reload data\n",
        "rec = np.load(SPATH+'fig2c_data.npz', allow_pickle=True)['rec'].item()\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(1.4,1.4))\n",
        "\n",
        "true_sigma = np.log2(rec['input']['sigma'])\n",
        "avg_sigma = np.log2(rec['hyp']['sigma'])\n",
        "err_sigma = rec['hess_info']['hyp_std'][:3]\n",
        "for i, c in enumerate(sim_colors):\n",
        "    plt.plot([2*i-0.3, 2*i+0.3], [true_sigma[i]]*2, color=\"black\", linestyle=\"-\", lw=1.2, zorder=0)\n",
        "    plt.errorbar([2*i], avg_sigma[i], yerr=1.96*err_sigma[i], c=c, lw=1, marker='o', markersize=5)\n",
        "\n",
        "true_sigma = np.log2(rec['input']['sigDay'])\n",
        "avg_sigma = np.log2(rec['hyp']['sigDay'])\n",
        "err_sigma = rec['hess_info']['hyp_std'][3:]\n",
        "for i, c in enumerate(sim_colors):\n",
        "    plt.plot([2*i-0.3+1, 2*i+0.3+1], [true_sigma[i]]*2, color=\"black\", linestyle=\"-\", lw=1.2, zorder=0)\n",
        "    plt.errorbar([2*i+1], avg_sigma[i], yerr=1.96*err_sigma[i], c=c, lw=1, marker='s', markersize=5)\n",
        "\n",
        "plt.axvspan(2.6,4.4, facecolor=\"black\", edgecolor=\"none\", alpha=0.1)\n",
        "plt.xticks(np.arange(6))\n",
        "plt.yticks([-8,-6,-4,-2,0,2])\n",
        "plt.gca().set_xticklabels([r\"$\\sigma_1$\", r\"$_{day}$\",\n",
        "                           r\"$\\sigma_2$\", r\"$_{day}$\",\n",
        "                           r\"$\\sigma_3$\", r\"$_{day}$\",])\n",
        "plt.xlim(-0.5,5.5); plt.ylim(-8.5,2.5)\n",
        "# plt.ylabel(r\"$\\log_2(\\sigma)$\")\n",
        "\n",
        "plt.gca().spines['right'].set_visible(False)\n",
        "plt.gca().spines['top'].set_visible(False)\n",
        "\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"Fig2d.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5yKnakcgfdR",
        "colab_type": "text"
      },
      "source": [
        "# Figure 3 | Visualization of Early Learning in IBL Mice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uc5xmlMVgfdS",
        "colab_type": "text"
      },
      "source": [
        "**(A)** A performance curve of an example mouse (`CSHL_003`) on easy trials during early training\n",
        "\n",
        "**(B)** Psychometric weights for the mouse and sessions shown in (A)\n",
        "\n",
        "**(C)** The performance curves of a subset (1 in 5) of the full population of mice on easy trials in early training (first 16 sessions)\n",
        "\n",
        "**(D)** Psychometric weights for all the mice shown in (C), plus average weights calculated from all mice in the population"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-23T07:22:32.432229Z",
          "start_time": "2020-01-23T07:22:32.387441Z"
        },
        "id": "HHb50rthgfdS",
        "colab_type": "text"
      },
      "source": [
        "## Figure 3a"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:24:33.814622Z",
          "start_time": "2020-04-18T01:24:32.012976Z"
        },
        "id": "SV7bAClvgfdT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import date, datetime, timedelta\n",
        "\n",
        "outData = getMouse('CSHL_003', 5)\n",
        "easy_trials = (outData['contrastLeft'] > 0.45).astype(int) | (outData['contrastRight'] > 0.45).astype(int)\n",
        "\n",
        "perf = []\n",
        "for d in np.unique(outData['date']):\n",
        "    date_trials = (outData['date'] == d).astype(int)\n",
        "    inds = (date_trials * easy_trials).astype(bool)\n",
        "    perf += [np.average(outData['correct'][inds])]\n",
        "\n",
        "dates = np.unique([datetime.strptime(i, \"%Y-%m-%d\") for i in outData['date']])\n",
        "dates = np.arange(len(dates)) + 1\n",
        "\n",
        "# Plotting\n",
        "fig = plt.figure(figsize=(2.75,0.9))\n",
        "\n",
        "plt.plot(dates[:16], perf[:16], color=\"black\", linewidth=1.5, zorder=2)\n",
        "plt.scatter(dates[9], perf[9], c=\"white\", s=30, edgecolors=\"black\", linestyle=\"--\", lw=0.75, zorder=5, alpha=1)\n",
        "\n",
        "plt.axhline(0.5, color=\"black\", linestyle=\"--\", lw=1, alpha=0.5, zorder=0)\n",
        "\n",
        "plt.xticks(np.arange(0,16,5))\n",
        "plt.yticks([0.4,0.6,0.8,1.0])\n",
        "plt.ylim(0.25,1.0)\n",
        "plt.xlim(1, 15.5)\n",
        "plt.gca().spines['right'].set_visible(False)\n",
        "plt.gca().spines['top'].set_visible(False)\n",
        "\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"Fig3a.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heJGyBnPgfdW",
        "colab_type": "text"
      },
      "source": [
        "## Figure 3b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:24:58.446636Z",
          "start_time": "2020-04-18T01:24:38.187152Z"
        },
        "id": "8_EacCqDgfdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Collect data from manually determined training period\n",
        "new_dat = psy.trim(outData, END=7000)\n",
        "\n",
        "# Compute\n",
        "weights = {'bias' : 0, 'cL' : 1, 'cR' : 1}\n",
        "K = np.sum([weights[i] for i in weights.keys()])\n",
        "hyper_guess = {\n",
        " 'sigma'   : [2**-5]*K,\n",
        " 'sigInit' : 2**5,\n",
        " 'sigDay'  : None\n",
        "  }\n",
        "optList = ['sigma']\n",
        "\n",
        "hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList)\n",
        "\n",
        "dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'W_std' : hess_info['W_std'],\n",
        "       'weights' : weights, 'new_dat' : new_dat}\n",
        "\n",
        "# Save interim result\n",
        "np.savez_compressed(SPATH+'fig3b_data.npz', dat=dat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:24:59.223528Z",
          "start_time": "2020-04-18T01:24:58.449959Z"
        },
        "id": "KueRXLwDgfdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dat = np.load(SPATH+'fig3b_data.npz', allow_pickle=True)['dat'].item()\n",
        "\n",
        "fig = psy.plot_weights(dat['wMode'], dat['weights'], days=dat['new_dat'][\"dayLength\"], \n",
        "                       errorbar=dat['W_std'], figsize=(2.75,1.3))\n",
        "\n",
        "plt.axvline(np.cumsum(dat['new_dat']['dayLength'])[8], c=\"black\", lw=1.5, ls=\"--\", zorder=15)\n",
        "plt.ylim(-5.3,5.3)\n",
        "plt.xlim(0, 6950)\n",
        "plt.yticks([-4,-2,0,2,4])\n",
        "plt.xlabel(None); plt.ylabel(None)\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"Fig3b.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IFbRzjjgfdb",
        "colab_type": "text"
      },
      "source": [
        "## Figure 3c\n",
        "\n",
        "_2 min_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:26:40.808120Z",
          "start_time": "2020-04-18T01:25:09.451346Z"
        },
        "id": "kmsmdVxhgfdb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import date, datetime, timedelta\n",
        "\n",
        "all_dates = []\n",
        "all_perf = []\n",
        "for s in np.unique(mouseData['subject']):\n",
        "    outData = getMouse(s, 5)\n",
        "    easy_trials = (outData['contrastLeft'] > 0.45).astype(int) | (outData['contrastRight'] > 0.45).astype(int)\n",
        "\n",
        "    perf = []\n",
        "    for d in np.unique(outData['date']):\n",
        "        date_trials = (outData['date'] == d).astype(int)\n",
        "        inds = (date_trials * easy_trials).astype(bool)\n",
        "        perf += [np.average(outData['correct'][inds])]\n",
        "\n",
        "    dates = np.unique([datetime.strptime(i, \"%Y-%m-%d\") for i in outData['date']])\n",
        "    dates = np.arange(len(dates))\n",
        "    \n",
        "    all_dates += [dates]\n",
        "    all_perf += [perf]\n",
        "    \n",
        "x = [[] for i in range(25)]\n",
        "for dates, perf in zip(all_dates, all_perf):\n",
        "    for ind, d in enumerate(dates):\n",
        "        if d < 25:\n",
        "            x[d] += [perf[ind]]\n",
        "perf_avg = [np.average(i) for i in x] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:26:41.277035Z",
          "start_time": "2020-04-18T01:26:40.810891Z"
        },
        "id": "v2PCwuhdgfde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(2.75,0.9))\n",
        "\n",
        "for dates, perf in zip(all_dates[::8], all_perf[::8]):\n",
        "    plt.plot(dates[:25], perf[:25], color=\"black\", linewidth=1, alpha=0.2, zorder=1)\n",
        "\n",
        "plt.plot(perf_avg[:25], color=\"black\", lw=2.5, alpha=0.8, zorder=6)\n",
        "\n",
        "plt.axhline(0.5, color=\"black\", linestyle=\"--\", lw=1, alpha=0.5, zorder=0)\n",
        "\n",
        "plt.xticks(np.arange(0,16,5))\n",
        "plt.yticks([0.4,0.6,0.8,1.0])\n",
        "plt.ylim(0.25,1.0)\n",
        "plt.xlim(1, 15.5)\n",
        "plt.gca().set_yticklabels([])\n",
        "\n",
        "plt.gca().spines['right'].set_visible(False)\n",
        "plt.gca().spines['top'].set_visible(False)\n",
        "\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"Fig3c.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSHx0hK_gfdh",
        "colab_type": "text"
      },
      "source": [
        "## Figure 3d\n",
        "_20 min_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:44:55.583172Z",
          "start_time": "2020-04-18T01:26:41.279989Z"
        },
        "id": "Z5caxLeWgfdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, s in enumerate(np.unique(mouseData['subject'])):\n",
        "\n",
        "    print(\"\\rProcessing \" + str(i+1) + \" of \" + str(len(mouseData[\"subject\"].unique())), end=\"\")\n",
        "\n",
        "    outData = getMouse(s, 5)\n",
        "    \n",
        "    # Collect data from manually determined training period\n",
        "    new_dat = psy.trim(outData, END=7000)\n",
        "\n",
        "    # Compute\n",
        "    weights = {'bias' : 0, 'cL' : 1, 'cR' : 1}\n",
        "    K = np.sum([weights[i] for i in weights.keys()])\n",
        "    hyper_guess = {\n",
        "     'sigma'   : [2**-5]*K,\n",
        "     'sigInit' : 2**5,\n",
        "     'sigDay'  : None\n",
        "      }\n",
        "    optList = ['sigma']\n",
        "\n",
        "    hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList, hess_calc=None)\n",
        "\n",
        "    dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'hess_info' : hess_info,\n",
        "           'weights' : weights, 'new_dat' : new_dat}\n",
        "\n",
        "    # Save interim result\n",
        "    np.savez_compressed(SPATH+'fig3c_'+s+'_data.npz', dat=dat)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:44:57.266324Z",
          "start_time": "2020-04-18T01:44:55.585987Z"
        },
        "scrolled": false,
        "id": "9vP7uGz6gfdj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(2.75,1.3))\n",
        "w0 = []\n",
        "w1 = []\n",
        "for i, s in enumerate(np.unique(mouseData['subject'])):\n",
        "\n",
        "    dat = np.load(SPATH+'fig3c_'+s+'_data.npz', allow_pickle=True)['dat'].item()\n",
        "\n",
        "    w0 += [np.hstack((dat['wMode'][0][:7000], [np.nan]*(7000 - len(dat['wMode'][0][:7000]))))]\n",
        "    w1 += [np.hstack((dat['wMode'][1][:7000], [np.nan]*(7000 - len(dat['wMode'][1][:7000]))))]\n",
        "\n",
        "    if not i%8:\n",
        "        plt.plot(dat['wMode'][0], color=colors['cL'], lw=1, alpha=0.2, zorder=4)\n",
        "        plt.plot(dat['wMode'][1], color=colors['cR'], lw=1, alpha=0.2, zorder=2)\n",
        "\n",
        "    \n",
        "plt.plot(np.nanmean(w0, axis=0), color=colors['cL'], lw=2.5, alpha=0.8, zorder=6)\n",
        "plt.plot(np.nanmean(w1, axis=0), color=colors['cR'], lw=2.5, alpha=0.8, zorder=6)\n",
        "plt.axhline(0, linestyle='--', color=\"black\", lw=1, alpha=0.5, zorder=0)\n",
        "plt.ylim(-5.3,5.3)\n",
        "plt.xlim(0, 6950)\n",
        "plt.yticks([-4,-2,0,2,4])\n",
        "plt.gca().set_yticklabels([])\n",
        "\n",
        "plt.gca().spines['right'].set_visible(False)\n",
        "plt.gca().spines['top'].set_visible(False)\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"Fig3d.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAHhUULfgfdm",
        "colab_type": "text"
      },
      "source": [
        "# Figure 4 | Adaptation to Bias Blocks in an Example IBL Mouse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1PKTl-5gfdm",
        "colab_type": "text"
      },
      "source": [
        "**(A)** Show performance curve of example mouse on easy trials, highlight different training periods\n",
        "\n",
        "**(B)** Show data for early bias blocks of example mouse\n",
        "\n",
        "**(C)** Show data for late bias blocks of example mouse\n",
        "\n",
        "**(D)** For early bias blocks (B), chunk the bias weight by block, plot how the weight changes from start to end of each block\n",
        "\n",
        "**(E)** Same as (D) but for late bias blocks (C)\n",
        "\n",
        "**(F)** Overlay optimal bias weight on the 2nd session shown in (C)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5lR5MiYgfdn",
        "colab_type": "text"
      },
      "source": [
        "## Figure 4a"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:45:06.682753Z",
          "start_time": "2020-04-18T01:45:05.006787Z"
        },
        "id": "iZe0MFy3gfdn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import date, datetime, timedelta\n",
        "\n",
        "outData = getMouse(\"CSHL_003\", 5)\n",
        "easy_trials = (outData['contrastLeft'] > 0.45).astype(int) | (outData['contrastRight'] > 0.45).astype(int)\n",
        "\n",
        "perf = []\n",
        "for d in np.unique(outData['date']):\n",
        "    date_trials = (outData['date'] == d).astype(int)\n",
        "    inds = (date_trials * easy_trials).astype(bool)\n",
        "    perf += [np.average(outData['correct'][inds])]\n",
        "\n",
        "dates = [datetime.strptime(i, \"%Y-%m-%d\") for i in outData['date']]\n",
        "dates = np.arange(len(dates)) + 1\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(3.5,0.9))\n",
        "plt.plot(dates[:52], perf[:52], color=\"black\", linewidth=1.5, zorder=2)\n",
        "\n",
        "plt.axhline(0.5, linestyle='--', color=\"black\", lw=1, alpha=0.5, zorder=1)\n",
        "plt.yticks([0.4,0.6,0.8,1.0])\n",
        "plt.ylim(0.25,1)\n",
        "plt.xlim(1,47)\n",
        "plt.gca().spines['right'].set_visible(False)\n",
        "plt.gca().spines['top'].set_visible(False)\n",
        "#plt.ylabel(\"Performance\\n(on easy trials)\")\n",
        "#plt.xlabel(\"Weeks of Training\")\n",
        "\n",
        "plt.axvspan(0,17.5, ymax=1,\n",
        "            edgecolor='None', alpha=0.1, facecolor=\"black\", zorder=0)\n",
        "plt.axvspan(16.5,19.5, linestyle=\"-\", lw=2.5, ymin=0.03, ymax=0.98,\n",
        "            edgecolor='#E32D91', alpha=.8, facecolor=\"None\", zorder=8)\n",
        "plt.axvspan(43.5,45.5, linestyle=\"-\", lw=2.5, ymin=0.03, ymax=0.98,\n",
        "            edgecolor='#9252AB', alpha=.8, facecolor=\"None\", zorder=9)\n",
        "\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"Fig4a.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MISkYx9gfds",
        "colab_type": "text"
      },
      "source": [
        "## Figure 4b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:45:44.476264Z",
          "start_time": "2020-04-18T01:45:09.894803Z"
        },
        "id": "MDLG3Ochgfds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Collect data from manually determined training period\n",
        "outData = getMouse(\"CSHL_003\", 5)\n",
        "_start  = np.where(outData['date'] >= '2019-03-21')[0][0]\n",
        "_end    = np.where(outData['date'] >= '2019-03-23')[0][0]\n",
        "new_dat = psy.trim(outData, START=_start, END=_end)\n",
        "\n",
        "# Hardcode random trials where probL != 0.5 before bias blocks begin to 0.5\n",
        "# (fyi, this is due to anti-biasing in the IBL early training protocol)\n",
        "new_dat['probL'][:np.where(new_dat['date'] >= '2019-03-22')[0][0]] = 0.5\n",
        "\n",
        "# Compute\n",
        "weights = {'bias' : 1, 'cL' : 1, 'cR' : 1}\n",
        "K = np.sum([weights[i] for i in weights.keys()])\n",
        "hyper_guess = {\n",
        " 'sigma'   : [2**-5]*K,\n",
        " 'sigInit' : 2**5,\n",
        " 'sigDay'  : [2**-5]*K\n",
        "  }\n",
        "optList = ['sigma', 'sigDay']\n",
        "\n",
        "hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList)\n",
        "\n",
        "dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'W_std' : hess_info['W_std'],\n",
        "       'weights' : weights, 'new_dat' : new_dat}\n",
        "\n",
        "# Save interim result\n",
        "np.savez_compressed(SPATH+'fig4b_data.npz', dat=dat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:45:44.535995Z",
          "start_time": "2020-04-18T01:45:44.478715Z"
        },
        "id": "CDNppZ_8gfdx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BIAS_COLORS = {50 : 'None', 20 : psy.COLORS['sR'], 80 : psy.COLORS['sL']}\n",
        "def addBiasBlocks(fig, pL):\n",
        "    plt.sca(fig.gca())\n",
        "    i = 0\n",
        "    while i < len(pL):\n",
        "        start = i\n",
        "        while i+1 < len(pL) and np.linalg.norm(pL[i] - pL[i+1]) < 0.0001:\n",
        "            i += 1\n",
        "        fc = BIAS_COLORS[int(100 * pL[start])]\n",
        "        plt.axvspan(start, i+1, facecolor=fc, alpha=0.2, edgecolor=None)\n",
        "        i += 1\n",
        "    return fig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:45:45.273854Z",
          "start_time": "2020-04-18T01:45:44.540219Z"
        },
        "id": "ZvWzus2bgfdz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dat = np.load(SPATH+'fig4b_data.npz', allow_pickle=True)['dat'].item()\n",
        "\n",
        "fig = psy.plot_weights(dat['wMode'], dat['weights'], days=dat['new_dat'][\"dayLength\"], \n",
        "                       errorbar=dat['W_std'], figsize=(2.75,1.3))\n",
        "fig = addBiasBlocks(fig, dat['new_dat']['probL'])\n",
        "\n",
        "plt.xlabel(None); plt.ylabel(None)\n",
        "plt.gca().set_yticks(np.arange(-6, 7,2))\n",
        "plt.ylim(-5.3,5.3)\n",
        "\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"Fig4b.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iI3P1GZlgfd2",
        "colab_type": "text"
      },
      "source": [
        "## Figure 4c"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:46:57.043289Z",
          "start_time": "2020-04-18T01:46:26.469282Z"
        },
        "id": "yqTvpd2Bgfd2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Collect data from manually determined training period\n",
        "outData = getMouse(\"CSHL_003\", 5)\n",
        "_start  = np.where(outData['date'] >= '2019-04-30')[0][0]\n",
        "_end    = np.where(outData['date'] >= '2019-05-02')[0][0]\n",
        "new_dat = psy.trim(outData, START=_start, END=_end)\n",
        "\n",
        "# Compute\n",
        "weights = {'bias' : 1, 'cL' : 1, 'cR' : 1}\n",
        "K = np.sum([weights[i] for i in weights.keys()])\n",
        "hyper_guess = {\n",
        " 'sigma'   : [2**-5]*K,\n",
        " 'sigInit' : 2**5,\n",
        " 'sigDay'  : [2**-5]*K\n",
        "  }\n",
        "optList = ['sigma', 'sigDay']\n",
        "\n",
        "hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList)\n",
        "\n",
        "dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'W_std' : hess_info['W_std'],\n",
        "       'weights' : weights, 'new_dat' : new_dat}\n",
        "\n",
        "# Save interim result\n",
        "np.savez_compressed(SPATH+'fig4c_data.npz', dat=dat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:46:57.738587Z",
          "start_time": "2020-04-18T01:46:57.045770Z"
        },
        "id": "ljpEqBWegfd5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dat = np.load(SPATH+'fig4c_data.npz', allow_pickle=True)['dat'].item()\n",
        "\n",
        "fig = psy.plot_weights(dat['wMode'], dat['weights'], days=dat['new_dat'][\"dayLength\"], \n",
        "                       errorbar=dat['W_std'], figsize=(2.75,1.3))\n",
        "fig = addBiasBlocks(fig, dat['new_dat']['probL'])\n",
        "\n",
        "plt.xlabel(None); plt.ylabel(None)\n",
        "plt.gca().set_yticks(np.arange(-6, 7,2))\n",
        "plt.gca().set_yticklabels([])\n",
        "plt.ylim(-5.3,5.3)\n",
        "\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"Fig4c.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnS7N25fgfd8",
        "colab_type": "text"
      },
      "source": [
        "## Figure 4d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:47:50.006569Z",
          "start_time": "2020-04-18T01:46:57.741749Z"
        },
        "id": "fZZyS8Q0gfd9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outData = getMouse(\"CSHL_003\", 5)\n",
        "\n",
        "# Collect data from manually determined training period\n",
        "_start  = np.where(outData['date'] >= '2019-03-22')[0][0]\n",
        "_end    = np.where(outData['date'] >= '2019-03-26')[0][0]\n",
        "new_dat = psy.trim(outData, START=_start, END=_end)\n",
        "\n",
        "# Hardcode random trials where probL != 0.5 before bias begins to 0.5\n",
        "# (fyi, this is due to anti-biasing in the IBL early training protocol)\n",
        "new_dat['probL'][:np.where(new_dat['date'] >= '2019-03-22')[0][0]] = 0.5\n",
        "\n",
        "# Compute\n",
        "weights = {'bias' : 1, 'cL' : 1, 'cR' : 1}\n",
        "K = np.sum([weights[i] for i in weights.keys()])\n",
        "hyper_guess = {\n",
        " 'sigma'   : [2**-5]*K,\n",
        " 'sigInit' : 2**5,\n",
        " 'sigDay'  : [2**-5]*K\n",
        "  }\n",
        "optList = ['sigma', 'sigDay']\n",
        "\n",
        "hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList)\n",
        "\n",
        "dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'W_std' : hess_info['W_std'],\n",
        "       'weights' : weights, 'new_dat' : new_dat}\n",
        "\n",
        "# Save interim result\n",
        "np.savez_compressed(SPATH+'fig4d_data.npz', dat=dat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:47:50.732024Z",
          "start_time": "2020-04-18T01:47:50.010315Z"
        },
        "id": "mSFEQLBjgfd_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bias_diff(dat_load, figsize=(1.5,1.5)):\n",
        "    dat = np.load(dat_load, allow_pickle=True)['dat'].item()\n",
        "    pL = dat['new_dat']['probL']\n",
        "    pL_diff = pL[1:] - pL[:-1]\n",
        "    inds = np.where(pL_diff)[0]\n",
        "    start_inds = [0] + list(inds+1)\n",
        "    start_inds = [i for i in start_inds if (np.isclose(pL[i], 0.2) or np.isclose(pL[i], 0.8))]\n",
        "    end_inds = list(inds) + [len(pL)-1]\n",
        "    end_inds = [i for i in end_inds if (np.isclose(pL[i], 0.2) or np.isclose(pL[i], 0.8))]\n",
        "\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    for s, e in zip(start_inds, end_inds):\n",
        "        if e-s < 20: continue\n",
        "        block_inds = np.arange(s, e+1)\n",
        "        block = dat['wMode'][0, block_inds] - dat['wMode'][0, s]\n",
        "        if np.isclose(pL[s], 0.2):\n",
        "            plt.plot(block, color=colors['cR'], alpha=0.8, zorder=2, lw=1)\n",
        "        else:\n",
        "            plt.plot(block, color=colors['cL'], alpha=0.8, zorder=4, lw=1)\n",
        "    \n",
        "    plt.axhline(0, linestyle='--', color=\"black\", lw=1, alpha=0.5, zorder=0)\n",
        "    plt.ylim(-5.5,5.5)\n",
        "    plt.xlim(0, 75)\n",
        "\n",
        "    plt.gca().spines['right'].set_visible(False)\n",
        "    plt.gca().spines['top'].set_visible(False)\n",
        "    plt.subplots_adjust(0,0,1,1)\n",
        "    return fig\n",
        "\n",
        "fig = bias_diff(SPATH+'fig4d_data.npz', figsize=(1.3,1.3));\n",
        "plt.gca().set_yticks([-4,-2,0,2,4])\n",
        "plt.savefig(SPATH + \"Fig4d.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhkc0tHOgfeB",
        "colab_type": "text"
      },
      "source": [
        "## Figure 4e"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:48:54.924739Z",
          "start_time": "2020-04-18T01:47:50.735178Z"
        },
        "id": "9AF7CKazgfeB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outData = getMouse(\"CSHL_003\", 5)\n",
        "\n",
        "# Collect data from manually determined training period\n",
        "_start  = np.where(outData['date'] >= '2019-04-30')[0][0]\n",
        "_end    = np.where(outData['date'] >= '2019-05-03')[0][0]\n",
        "new_dat = psy.trim(outData, START=_start, END=_end)\n",
        "\n",
        "# Compute\n",
        "weights = {'bias' : 1, 'cL' : 1, 'cR' : 1}\n",
        "K = np.sum([weights[i] for i in weights.keys()])\n",
        "hyper_guess = {\n",
        " 'sigma'   : [2**-5]*K,\n",
        " 'sigInit' : 2**5,\n",
        " 'sigDay'  : [2**-5]*K\n",
        "  }\n",
        "optList = ['sigma', 'sigDay']\n",
        "\n",
        "hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList)\n",
        "\n",
        "dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'W_std' : hess_info['W_std'],\n",
        "       'weights' : weights, 'new_dat' : new_dat}\n",
        "\n",
        "# Save interim result\n",
        "np.savez_compressed(SPATH+'fig4e_data.npz', dat=dat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:48:55.574446Z",
          "start_time": "2020-04-18T01:48:54.927119Z"
        },
        "id": "xZTvGEdcgfeE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = bias_diff(SPATH+'fig4e_data.npz', figsize=(1.3,1.3));\n",
        "plt.gca().set_yticks([-4,-2,0,2,4])\n",
        "plt.gca().set_yticklabels([])\n",
        "plt.savefig(SPATH + \"Fig4e.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edqcfySmgfeH",
        "colab_type": "text"
      },
      "source": [
        "## Figure 4f"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:48:55.632958Z",
          "start_time": "2020-04-18T01:48:55.576832Z"
        },
        "id": "EKpMHbPFgfeH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_bias(bias, side, wL, wR):\n",
        "        \n",
        "    contrasts = np.array([-1., -0.25, -0.125, -0.0625, 0., 0.0625, 0.125, 0.25, 1.])\n",
        "    \n",
        "    p=5\n",
        "    transformed_con = np.tanh(p*np.abs(contrasts))/np.tanh(p)\n",
        "\n",
        "    p_biasL = [.8/4.5]*4 + [1/9] + [.2/4.5]*4    \n",
        "    p_biasR = [.2/4.5]*4 + [1/9] + [.8/4.5]*4\n",
        "    p_biasM = [1/9]*9\n",
        "\n",
        "    w = [wL]*4 + [0] + [wR]*4\n",
        "    correct = [0]*4 + [0] + [1]*4\n",
        "\n",
        "    pL = 1 - (1/(1+np.exp(-(transformed_con*w + bias))))\n",
        "    pCorrect = np.abs(correct - pL)\n",
        "    \n",
        "    if side==\"L\":\n",
        "        pCorrect[4] = pL[4]*0.8 + (1-pL[4])*0.2\n",
        "        expval = np.sum(p_biasL * pCorrect)\n",
        "    \n",
        "    elif side==\"R\":\n",
        "        pCorrect[4] = pL[4]*0.2 + (1-pL[4])*0.8\n",
        "        expval = np.sum(p_biasR * pCorrect)\n",
        "    \n",
        "    elif side==\"M\":\n",
        "        pCorrect[4] = 0.5\n",
        "        expval = np.sum(p_biasM * pCorrect)\n",
        "    \n",
        "    return -expval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:48:57.445049Z",
          "start_time": "2020-04-18T01:48:55.637573Z"
        },
        "id": "gKSLfL5ggfeL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.optimize import minimize\n",
        "\n",
        "dat = np.load(SPATH+'fig4c_data.npz', allow_pickle=True)['dat'].item()\n",
        "start = dat['new_dat']['dayLength'][0]\n",
        "\n",
        "optBias = []\n",
        "optReward = []\n",
        "for i in np.arange(start, dat['wMode'].shape[1]):\n",
        "    \n",
        "    if dat['new_dat']['probL'][i] < 0.21: side = 'R'\n",
        "    elif dat['new_dat']['probL'][i] > 0.79: side = 'L'\n",
        "    else: side = 'M'\n",
        "        \n",
        "    res = minimize(max_bias,[0], args=(side, dat['wMode'][1,i], dat['wMode'][2,i]))\n",
        "    optBias += [res.x]\n",
        "    optReward += [-res.fun]\n",
        "\n",
        "print(\"Avg. Reward:\", np.mean(optReward))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:48:58.070451Z",
          "start_time": "2020-04-18T01:48:57.448083Z"
        },
        "id": "nkVwSTSUgfeO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = psy.plot_weights(dat['wMode'], dat['weights'], days=dat['new_dat'][\"dayLength\"],\n",
        "                       errorbar=dat['W_std'], figsize=(2.75,1.3))\n",
        "fig = addBiasBlocks(fig, dat['new_dat']['probL'])\n",
        "\n",
        "plt.plot(np.arange(start, dat['wMode'].shape[1]), optBias, 'k-', lw=2, zorder=10)\n",
        "plt.gca().set_yticks(np.arange(-6, 7,2))\n",
        "plt.gca().set_yticklabels([])\n",
        "plt.gca().set_xticks([750, 1000, 1250])\n",
        "plt.xlim(start, None); plt.ylim(-5.3,5.3)\n",
        "plt.xlabel(None); plt.ylabel(None)\n",
        "\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"Fig4f.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T01:48:58.292918Z",
          "start_time": "2020-04-18T01:48:58.074129Z"
        },
        "id": "_EzFYonvgfeQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Actual predicted reward using actual bias weight\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "optReward_pred = []\n",
        "optReward_0bias = []\n",
        "for i in np.arange(start, dat['wMode'].shape[1]):\n",
        "    \n",
        "    if dat['new_dat']['probL'][i] < 0.21: side = 'R'\n",
        "    elif dat['new_dat']['probL'][i] > 0.79: side = 'L'\n",
        "    else: side = 'M'\n",
        "        \n",
        "    optReward_pred += [-max_bias(dat['wMode'][0,i], side, dat['wMode'][1,i], dat['wMode'][2,i])]\n",
        "    optReward_0bias += [-max_bias(0.0, side, dat['wMode'][1,i], dat['wMode'][2,i])]\n",
        "\n",
        "print(\"Predicted Avg. Reward:\", np.mean(optReward_pred))\n",
        "print(\"No Bias Avg. Reward:\", np.mean(optReward_0bias))\n",
        "print(\"Empirical Avg. Reward:\", np.mean(dat['new_dat']['correct'][start:]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWTR9owcgfeW",
        "colab_type": "text"
      },
      "source": [
        "# Figure 5 | Visualization of Learning in an Example Akrami Rat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91n_SNbVgfeW",
        "colab_type": "text"
      },
      "source": [
        "**(A)** Akrami rat task schematic (Illustrator only)\n",
        "\n",
        "**(B)** Psychometric weights for an example rat (`W080`)\n",
        " \n",
        "**(C)** Show performance tracking on rat shown in (B)\n",
        "\n",
        "**(D)** Show bias tracking on rat shown in (B)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ohWyMHGgfeX",
        "colab_type": "text"
      },
      "source": [
        "## Figure 5b\n",
        "\n",
        "_14 min_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T02:04:08.046571Z",
          "start_time": "2020-04-18T01:50:15.385773Z"
        },
        "id": "iXDZq3HkgfeX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outData = getRat(\"W080\")\n",
        "new_dat = psy.trim(outData, END=12500)\n",
        "\n",
        "# Compute\n",
        "weights = {'bias': 1, 's_a': 1, 's_b': 1, 'h': 1, 'c': 1, \"s_avg\": 1}\n",
        "K = np.sum([weights[i] for i in weights.keys()])\n",
        "hyper_guess = {\n",
        " 'sigma'   : [2**-5]*K,\n",
        " 'sigInit' : 2**5,\n",
        " 'sigDay'  : [2**-4]*K,\n",
        "  }\n",
        "optList = ['sigma', 'sigDay']\n",
        "\n",
        "hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList)\n",
        "\n",
        "dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'W_std' : hess_info['W_std'],\n",
        "       'weights' : weights, 'new_dat' : new_dat}\n",
        "\n",
        "# Save interim result\n",
        "np.savez_compressed(SPATH+'fig5b_data.npz', dat=dat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T02:04:09.643751Z",
          "start_time": "2020-04-18T02:04:08.049537Z"
        },
        "id": "5CneCsBugfeZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dat = np.load(SPATH+'fig5b_data.npz', allow_pickle=True)['dat'].item()\n",
        "\n",
        "fig = psy.plot_weights(dat['wMode'], dat['weights'], days=dat['new_dat'][\"dayLength\"], \n",
        "                       errorbar=dat['W_std'], figsize=(4.75,1.4))\n",
        "\n",
        "plt.xlabel(None); plt.ylabel(None)\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"Fig5b.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcpZm7Q-gfeb",
        "colab_type": "text"
      },
      "source": [
        "## Figure 5c\n",
        "\n",
        "_2.5 hours_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T05:23:00.094330Z",
          "start_time": "2020-04-18T02:45:55.665177Z"
        },
        "id": "qsj4MPeegfec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outData = getRat(\"W080\")\n",
        "new_dat = psy.trim(outData, END=12500)\n",
        "\n",
        "FOLDS = 10  # number of cross-validation folds\n",
        "SEED = 42   # controls random divide of trials into FOLDS bins\n",
        "\n",
        "weights = {'bias': 1, 's_a': 1, 's_b': 1, 'h': 1, 'c': 1, \"s_avg\": 1}\n",
        "K = np.sum([weights[i] for i in weights.keys()])\n",
        "hyper_guess = {\n",
        " 'sigma'   : [2**-5]*K,\n",
        " 'sigInit' : 2**5,\n",
        " 'sigDay'  : [2**-4]*K,\n",
        "  }\n",
        "optList = ['sigma', 'sigDay']\n",
        "\n",
        "_, xval_pL = psy.crossValidate(new_dat, hyper_guess, weights, optList, F=FOLDS, seed=SEED)\n",
        "np.savez_compressed(SPATH+'fig5c_data.npz', new_dat=new_dat, xval_pL=xval_pL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-19T03:22:31.506257Z",
          "start_time": "2020-04-19T03:22:30.623298Z"
        },
        "id": "S9Ymgn49gfee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xval_pL = np.load(SPATH+'fig5c_data.npz', allow_pickle=True)['xval_pL'] \n",
        "new_dat = np.load(SPATH+'fig5c_data.npz', allow_pickle=True)['new_dat'].item()\n",
        "\n",
        "psy.plot_performance(new_dat, xval_pL=xval_pL, sigma=50, figsize=(4.75,1))\n",
        "\n",
        "plt.xlabel(None); plt.ylabel(None)\n",
        "plt.gca().set_yticks([0.4,0.5,0.6,0.7,0.8])\n",
        "plt.gca().set_yticklabels([0.4, None,0.6,None,0.8])\n",
        "plt.ylim(0.35,0.8)\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"Fig5c.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ha98e1e8gfei",
        "colab_type": "text"
      },
      "source": [
        "## Figure 5d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-19T03:22:44.359718Z",
          "start_time": "2020-04-19T03:22:43.462688Z"
        },
        "id": "RvMVQQLRgfej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xval_pL = np.load(SPATH+'fig5c_data.npz', allow_pickle=True)['xval_pL'] \n",
        "new_dat = np.load(SPATH+'fig5c_data.npz', allow_pickle=True)['new_dat'].item()\n",
        "\n",
        "psy.plot_bias(new_dat, xval_pL=xval_pL, sigma=50, figsize=(4.75,1))\n",
        "\n",
        "plt.xlabel(None); plt.ylabel(None)\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"Fig5d.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvHbOKpcgfel",
        "colab_type": "text"
      },
      "source": [
        "# Figure 6 | Population Psychometric Weights from Akrami Rats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lO9HJIvCgfel",
        "colab_type": "text"
      },
      "source": [
        "**(A)** Show overlay of population weights (including the average weights) for Tones A + B\n",
        "\n",
        "**(B)** For the Bias weight\n",
        "\n",
        "**(C)** For the Previous Tones weight\n",
        "\n",
        "**(D)** For the Previous (Correct) Answer weight\n",
        "\n",
        "**(E)** For the Previous Choice weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-n6NsStgfem",
        "colab_type": "text"
      },
      "source": [
        "## Figure 6a\n",
        "\n",
        "_6 hours_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T11:44:15.987858Z",
          "start_time": "2020-04-18T06:05:41.439554Z"
        },
        "id": "4stfPHurgfem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_rats = RAT_DF[\"subject_id\"].unique()\n",
        "for i, subject in enumerate(all_rats):\n",
        "\n",
        "    print(\"\\rProcessing \" + str(i+1) + \" of \" + str(len(all_rats)), end=\"\")\n",
        "        \n",
        "    outData = getRat(subject)\n",
        "\n",
        "    # Collect data from manually determined training period\n",
        "    new_dat = psy.trim(outData, END=20000)\n",
        "\n",
        "    # Compute\n",
        "    weights = {'bias': 1, 's_a': 1, 's_b': 1, 'h': 1, 'c': 1, \"s_avg\": 1}\n",
        "    K = np.sum([weights[i] for i in weights.keys()])\n",
        "    hyper_guess = {\n",
        "     'sigma'   : [2**-5]*K,\n",
        "     'sigInit' : 2**5,\n",
        "     'sigDay'  : [2**-4]*K,\n",
        "      }\n",
        "    optList = ['sigma', 'sigDay']\n",
        "\n",
        "    hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList, hess_calc=None)\n",
        "\n",
        "    dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'hess_info' : hess_info,\n",
        "           'weights' : weights, 'new_dat' : new_dat}\n",
        "\n",
        "    # Save interim result\n",
        "    np.savez_compressed(SPATH+'fig6a_'+subject+'_data.npz', dat=dat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T11:44:17.751283Z",
          "start_time": "2020-04-18T11:44:15.990400Z"
        },
        "id": "AT1zPOzYgfeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_labels = []\n",
        "all_w = []\n",
        "for subject in RAT_DF[\"subject_id\"].unique():\n",
        "    rat = np.load(SPATH+'fig6a_'+subject+'_data.npz', allow_pickle=True)['dat'].item()\n",
        "    \n",
        "    labels = []\n",
        "    for j in sorted(rat['weights'].keys()):\n",
        "        labels += [j]*rat['weights'][j]\n",
        "        \n",
        "    all_labels += [np.array(labels)]\n",
        "    all_w += [rat['wMode']] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T11:44:17.818016Z",
          "start_time": "2020-04-18T11:44:17.754525Z"
        },
        "id": "hSRx7yIKgfeq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_all(all_labels, all_w, Weights, figsize):\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    Weights = [Weights] if type(Weights) is str else Weights\n",
        "    avg_len=20000\n",
        "    for i, W in enumerate(Weights):\n",
        "        avg = []\n",
        "        for i in np.arange(0,len(all_w),1):\n",
        "            bias_ind = np.where(all_labels[i] == W)[0][0]\n",
        "            bias_w = all_w[i][bias_ind]\n",
        "            avg += [list(bias_w[:avg_len]) + [np.nan]*(avg_len - len(bias_w[:avg_len]))]\n",
        "            plt.plot(bias_w, color=colors[W], alpha=0.2, lw=1, zorder=2+i)\n",
        "        plt.plot(np.nanmean(avg, axis=0), color=colors[W], alpha=0.8, lw=2.5, zorder=5+i)\n",
        "\n",
        "    plt.axhline(0, color=\"black\", linestyle=\"--\", lw=1, alpha=0.5, zorder=1)\n",
        "    plt.gca().spines['right'].set_visible(False)\n",
        "    plt.gca().spines['top'].set_visible(False)\n",
        "    plt.xlim(0, 19000)\n",
        "    plt.ylim(-2.5, 2.5)\n",
        "    return fig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T21:15:19.109985Z",
          "start_time": "2020-04-18T21:15:17.723564Z"
        },
        "id": "-9GHjPakgfer",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_all(all_labels, all_w, [\"s_a\", \"s_b\"], (2.85, 1.2))\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"Fig6a.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuQzsIVhgfet",
        "colab_type": "text"
      },
      "source": [
        "## Figure 6b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T21:15:23.320322Z",
          "start_time": "2020-04-18T21:15:22.295349Z"
        },
        "id": "M09bpTRmgfeu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_all(all_labels, all_w, [\"bias\"], (2.85, 1.2))\n",
        "plt.gca().set_yticklabels([])\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"Fig6b.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0P3yj-Ogfex",
        "colab_type": "text"
      },
      "source": [
        "## Figure 6c"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T21:15:25.248590Z",
          "start_time": "2020-04-18T21:15:24.408445Z"
        },
        "id": "bZuiZdkwgfey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_all(all_labels, all_w, [\"s_avg\"], (1.85, 0.8))\n",
        "plt.ylim(-0.25, 2.25)\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"Fig6c.pdf\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckITmRUCgfe0",
        "colab_type": "text"
      },
      "source": [
        "## Figure 6d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T21:15:27.542700Z",
          "start_time": "2020-04-18T21:15:26.671576Z"
        },
        "id": "OxbHunnBgfe0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_all(all_labels, all_w, [\"h\"], (1.85, 0.8))\n",
        "plt.ylim(-0.25, 2.25)\n",
        "plt.gca().set_yticklabels([])\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"Fig6d.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afV-IoNYgfe2",
        "colab_type": "text"
      },
      "source": [
        "## Figure 6e"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T21:15:30.063634Z",
          "start_time": "2020-04-18T21:15:29.191788Z"
        },
        "id": "Y9hPucsRgfe2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_all(all_labels, all_w, [\"c\"], (1.85, 0.8))\n",
        "plt.ylim(-0.25, 2.25)\n",
        "plt.gca().set_yticklabels([])\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"Fig6e.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPnv6hCJgfe4",
        "colab_type": "text"
      },
      "source": [
        "# Figure 7 | Population Psychometric Weights from Akrami Human Subjects"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujrm8sVVgfe4",
        "colab_type": "text"
      },
      "source": [
        "**(A)** Athena human subject task schematic (Illustrator only)\n",
        "\n",
        "**(B)** Psychometric weights for an example human subject (`subject_id=6`)\n",
        "\n",
        "**(C)** Show psychometric weights for all human subjects together"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSXeM2Zqgfe7",
        "colab_type": "text"
      },
      "source": [
        "## Figure 7b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T05:30:57.233280Z",
          "start_time": "2020-04-18T05:30:42.020789Z"
        },
        "id": "phSPrpF6gfe7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_dat = getHuman(6)\n",
        "\n",
        "# Compute\n",
        "weights = {'bias': 1, 's_a': 1, 's_b': 1, 's_avg': 1}\n",
        "K = np.sum([weights[i] for i in weights.keys()])\n",
        "hyper_guess = {\n",
        " 'sigma'   : [2**-5]*K,\n",
        " 'sigInit' : 2**5,\n",
        " 'sigDay'  : None\n",
        "  }\n",
        "optList = ['sigma']\n",
        "\n",
        "hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList)\n",
        "\n",
        "dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'W_std' : hess_info['W_std'],\n",
        "       'weights' : weights, 'new_dat' : new_dat}\n",
        "\n",
        "# Save interim result\n",
        "np.savez_compressed(SPATH+'fig7b_data.npz', dat=dat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T05:30:57.812127Z",
          "start_time": "2020-04-18T05:30:57.235931Z"
        },
        "id": "kJeQ94q-gfe9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dat = np.load(SPATH+'fig7b_data.npz', allow_pickle=True)['dat'].item()\n",
        "fig = psy.plot_weights(dat['wMode'], dat['weights'], errorbar=dat['W_std'], figsize=(4.75,1))\n",
        "\n",
        "plt.xlabel(None); plt.ylabel(None)\n",
        "plt.gca().set_xticks([0,500,1000,1500,2000])\n",
        "plt.gca().set_yticks(np.arange(-2, 3,2))\n",
        "plt.xlim(0, 1900); plt.ylim(-3.4, 3.4)\n",
        "\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"Fig7b.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzYo_DEZgfe_",
        "colab_type": "text"
      },
      "source": [
        "## Figure 7c\n",
        "\n",
        "_3 min_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T05:34:09.463811Z",
          "start_time": "2020-04-18T05:32:00.008980Z"
        },
        "id": "CgdUOaK3gfe_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_dat = []\n",
        "all_subjects = HUMAN_DF[\"subject_id\"].unique()\n",
        "for i, subject in enumerate(all_subjects):\n",
        "    \n",
        "    print(\"\\rProcessing \" + str(i+1) + \" of \" + str(len(all_subjects)), end=\"\")\n",
        "\n",
        "    new_dat = getHuman(subject)\n",
        "\n",
        "    # Compute\n",
        "    weights = {'bias': 1, 's_a': 1, 's_b': 1, 's_avg': 1}\n",
        "    K = np.sum([weights[i] for i in weights.keys()])\n",
        "    hyper_guess = {\n",
        "     'sigma'   : [2**-5]*K,\n",
        "     'sigInit' : 2**5,\n",
        "     'sigDay'  : None\n",
        "      }\n",
        "    optList = ['sigma']\n",
        "\n",
        "    hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList)\n",
        "\n",
        "    dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'W_std' : hess_info['W_std'],\n",
        "           'weights' : weights, 'new_dat' : new_dat}\n",
        "    all_dat += [dat]\n",
        "\n",
        "# Save interim result\n",
        "np.savez_compressed(SPATH+'fig7c_data.npz', all_dat=all_dat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T05:34:10.219953Z",
          "start_time": "2020-04-18T05:34:09.466468Z"
        },
        "id": "qgpW3PaHgffB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_dat = np.load(SPATH+'fig7c_data.npz', allow_pickle=True)['all_dat']\n",
        "\n",
        "plt.figure(figsize=(4.75,1))\n",
        "for dat in all_dat:\n",
        "\n",
        "    weights = dat['weights']\n",
        "    wMode = dat['wMode']\n",
        "    labels = []\n",
        "    for j in sorted(weights.keys()):\n",
        "        labels += [j]*weights[j]\n",
        "\n",
        "    for i, w in enumerate(labels):\n",
        "        plt.plot(wMode[i], lw=1.5, alpha=0.5, linestyle='-', c=colors[w], zorder=zorder[w])\n",
        "\n",
        "plt.axhline(0, color=\"black\", linestyle=\"--\", lw=1, alpha=0.5, zorder=0)\n",
        "plt.gca().set_xticks([0,500,1000,1500,2000])\n",
        "plt.gca().set_yticks(np.arange(-2, 3,2))\n",
        "plt.xlim(0, 1900); plt.ylim(-3.4, 3.4)\n",
        "\n",
        "plt.gca().spines['right'].set_visible(False)\n",
        "plt.gca().spines['top'].set_visible(False)\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"Fig7c.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4DwBkzYgffD",
        "colab_type": "text"
      },
      "source": [
        "# Figure 8 | History Regressors Improve Model Accuracy for an Example Akrami Rat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awnKSjUvgffE",
        "colab_type": "text"
      },
      "source": [
        "**(A)** Show plot for model w/o using history weights: predicted accuracy on x-axis, and empirical accuracy on y-axis\n",
        "\n",
        "**(B)** Show histogram of trials from (A) from one rat of prediction strengths\n",
        "\n",
        "**(C)** Show plot for model with history weights: predicted accuracy on x-axis, and empirical accuracy on y-axis (reuses data from Figure 5c)\n",
        "\n",
        "**(D)** Show histogram of trials from (C) from one rat of prediction strengths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbXd5x2JgffF",
        "colab_type": "text"
      },
      "source": [
        "## Figure 8a\n",
        "\n",
        "_30 min_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T06:04:33.522786Z",
          "start_time": "2020-04-18T05:36:15.512179Z"
        },
        "id": "4wlqXPrxgffF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outData = getRat(\"W080\")\n",
        "new_dat = psy.trim(outData, END=12500)\n",
        "\n",
        "FOLDS = 10  # number of cross-validation folds\n",
        "SEED = 42   # controls random divide of trials into FOLDS bins\n",
        "\n",
        "weights = {'bias': 1, 's_a': 1, 's_b': 1, 'h': 0, 'c': 0, \"s_avg\": 0}\n",
        "K = np.sum([weights[i] for i in weights.keys()])\n",
        "hyper_guess = {\n",
        " 'sigma'   : [2**-5]*K,\n",
        " 'sigInit' : 2**5,\n",
        " 'sigDay'  : [2**-4]*K,\n",
        "  }\n",
        "optList = ['sigma', 'sigDay']\n",
        "\n",
        "_, xval_pL = psy.crossValidate(new_dat, hyper_guess, weights, optList, F=FOLDS, seed=SEED)\n",
        "np.savez_compressed(SPATH+'fig8a_data.npz', new_dat=new_dat, xval_pL=xval_pL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T06:04:34.220336Z",
          "start_time": "2020-04-18T06:04:33.526202Z"
        },
        "id": "H0OK6ZJjgffH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats import sem\n",
        "xval_pL = np.load(SPATH+'fig8a_data.npz', allow_pickle=True)['xval_pL'] \n",
        "new_dat = np.load(SPATH+'fig8a_data.npz', allow_pickle=True)['new_dat'].item()\n",
        "\n",
        "step = 0.02\n",
        "edges = np.arange(0.5,1.0+step,step)\n",
        "\n",
        "est_correct = np.abs(xval_pL - 0.5) + 0.5\n",
        "match = ((-np.sign(xval_pL - 0.5) + 1)/2).astype(int) == new_dat[\"y\"].astype(int)\n",
        "\n",
        "print(\"Average Empirical Accuracy:\", np.round(np.average(match), 3))\n",
        "print(\"Average Predicted Accuracy:\", np.round(np.average(est_correct), 3))\n",
        "\n",
        "choices = []\n",
        "centers = []\n",
        "for i in edges[:-1]:\n",
        "    mask = (est_correct >= i) & (est_correct < i+step)\n",
        "    choices += [match[mask]]\n",
        "    centers += [np.average(est_correct[mask])];\n",
        "\n",
        "avg_correct = np.array([np.average(i) if len(i) > 40 else np.nan for i in choices])\n",
        "sem_correct = np.array([sem(i) if len(i) > 40 else np.nan for i in choices])\n",
        "\n",
        "plt.figure(figsize=(2,1.5))\n",
        "plt.errorbar(centers, avg_correct, yerr=1.96*sem_correct,\n",
        "             alpha=1, color=colors['bias'], linestyle=\"None\", marker=\"o\", markersize=2)\n",
        "plt.plot(np.average(est_correct), np.average(match), marker=\"*\", markersize=10, alpha=0.75,\n",
        "         markeredgecolor=\"None\", markerfacecolor=\"black\", zorder=10)\n",
        "\n",
        "plt.plot([0.4,1.1], [0.4,1.1], color=\"black\", linestyle=\"--\", lw=1, alpha=0.5, zorder=0)\n",
        "\n",
        "plt.xlim(0.5, 1)\n",
        "plt.ylim(0.5, 1)\n",
        "plt.xticks([0.5,0.6,0.7,0.8,0.9,1.0])\n",
        "plt.gca().set_xticklabels([])\n",
        "\n",
        "plt.gca().spines['right'].set_visible(False)\n",
        "plt.gca().spines['top'].set_visible(False)\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"Fig8a.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MD64fWrYgffK",
        "colab_type": "text"
      },
      "source": [
        "## Figure 8b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T06:04:34.883172Z",
          "start_time": "2020-04-18T06:04:34.223286Z"
        },
        "id": "0eVXehmGgffL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(2,1.5))\n",
        "plt.hist(est_correct, bins=edges, alpha=1, lw=0.5, color=colors['bias'], edgecolor=\"black\")\n",
        "\n",
        "plt.xlim(0.5, 1)\n",
        "plt.ylim(0, 1700)\n",
        "plt.xticks([0.5,0.6,0.7,0.8,0.9,1.0])\n",
        "plt.gca().spines['right'].set_visible(False)\n",
        "plt.gca().spines['top'].set_visible(False)\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"Fig8b.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAeRQbfPgffN",
        "colab_type": "text"
      },
      "source": [
        "## Figure 8c\n",
        "\n",
        "_Reuses data generated in Figure 5c_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T05:35:36.113332Z",
          "start_time": "2020-04-18T05:35:35.821578Z"
        },
        "id": "QDqqPJ6TgffO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats import sem\n",
        "xval_pL = np.load(SPATH+'fig5c_data.npz', allow_pickle=True)['xval_pL'] \n",
        "new_dat = np.load(SPATH+'fig5c_data.npz', allow_pickle=True)['new_dat'].item()\n",
        "\n",
        "step = 0.02\n",
        "edges = np.arange(0.5,1.0+step,step)\n",
        "\n",
        "est_correct = np.abs(xval_pL - 0.5) + 0.5\n",
        "match = ((-np.sign(xval_pL - 0.5) + 1)/2).astype(int) == new_dat[\"y\"].astype(int)\n",
        "\n",
        "print(\"Average Empirical Accuracy:\", np.round(np.average(match), 3))\n",
        "print(\"Average Predicted Accuracy:\", np.round(np.average(est_correct), 3))\n",
        "\n",
        "choices = []\n",
        "centers = []\n",
        "for i in edges[:-1]:\n",
        "    mask = (est_correct >= i) & (est_correct < i+step)\n",
        "    choices += [match[mask]]\n",
        "    centers += [np.average(est_correct[mask])];\n",
        "\n",
        "avg_correct = np.array([np.average(i) if len(i) > 40 else np.nan for i in choices])\n",
        "sem_correct = np.array([sem(i) if len(i) > 40 else np.nan for i in choices])\n",
        "\n",
        "plt.figure(figsize=(2,1.5))\n",
        "plt.errorbar(centers, avg_correct, yerr=1.96*sem_correct,\n",
        "             alpha=1, color=colors['h'], linestyle=\"None\", marker=\"o\", markersize=2)\n",
        "plt.plot(np.average(est_correct), np.average(match), marker=\"*\", markersize=10, alpha=0.75,\n",
        "         markeredgecolor=\"None\", markerfacecolor=\"black\", zorder=10)\n",
        "\n",
        "plt.plot([0.4,1.1], [0.4,1.1], color=\"black\", linestyle=\"--\", lw=1, alpha=0.5, zorder=0)\n",
        "\n",
        "plt.xlim(0.5, 1)\n",
        "plt.ylim(0.5, 1)\n",
        "plt.xticks([0.5,0.6,0.7,0.8,0.9,1.0])\n",
        "plt.gca().set_xticklabels([])\n",
        "plt.gca().set_yticklabels([])\n",
        "\n",
        "plt.gca().spines['right'].set_visible(False)\n",
        "plt.gca().spines['top'].set_visible(False)\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"Fig8c.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sf0al5ewgffQ",
        "colab_type": "text"
      },
      "source": [
        "## Figure 8d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T05:35:42.443362Z",
          "start_time": "2020-04-18T05:35:41.840784Z"
        },
        "id": "duOzrCfWgffQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(2,1.5))\n",
        "plt.hist(est_correct, bins=edges, alpha=1, lw=0.5, color=colors['h'], edgecolor=\"black\")\n",
        "\n",
        "plt.xlim(0.5, 1)\n",
        "plt.ylim(0, 1700)\n",
        "plt.xticks([0.5,0.6,0.7,0.8,0.9,1.0])\n",
        "plt.gca().set_yticklabels([])\n",
        "plt.gca().spines['right'].set_visible(False)\n",
        "plt.gca().spines['top'].set_visible(False)\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"Fig8d.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1unS1kWgffU",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjpYNikwgffV",
        "colab_type": "text"
      },
      "source": [
        "# Supplementary Figures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2FBPmWtgffV",
        "colab_type": "text"
      },
      "source": [
        "**(S1a)** Show compute time\n",
        "\n",
        "**(S1b)** Show weight recovery accuracy\n",
        "\n",
        "**(S2a)** Refit model from Figure 3b, with history regressor weights\n",
        "\n",
        "**(S2b)** Refit model from Figure 3b, with bias weight\n",
        "\n",
        "**(S3a)** $\\tanh$ tranformation on IBL contrasts\n",
        "\n",
        "**(S3b)** Refit model from Figure 4b, without $\\tanh$ transformation\n",
        "\n",
        "**(S4a)** Refit model from Figure 6b, with history regressor weights\n",
        "\n",
        "**(S4b)** Refit models from Figure 6c, with history regressor weights (showing only those weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8wYF2mYgffW",
        "colab_type": "text"
      },
      "source": [
        "## Figure S1a\n",
        "\n",
        "_5 hours_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T11:44:17.907716Z",
          "start_time": "2020-04-18T07:45:23.591Z"
        },
        "id": "tFeRSZ7ZgffW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from psytrack.runSim import generateSim, recoverSim\n",
        "\n",
        "num_weights = [2,4,6]\n",
        "num_trials = 1000*np.array([1,2,4,8,16])\n",
        "num_simulations = 20\n",
        "\n",
        "results = []\n",
        "\n",
        "for N in num_trials:\n",
        "    for K in num_weights:\n",
        "        for i in range(num_simulations):\n",
        "            print(\"K =\", K, \"  N =\", N, \"  iter = \", i)\n",
        "            # Simulate data\n",
        "            seed = N+100*K+i\n",
        "            np.random.seed(seed)\n",
        "            hyper = {'sigma': 2**np.random.uniform(-7.5, -3.5, size=K), 'sigInit': 1.0}\n",
        "            dat = generateSim(K=K, N=N, hyper=hyper, boundary=5.0, iterations=1, seed=seed)\n",
        "            \n",
        "            # Recover data\n",
        "            try:\n",
        "                rec = recoverSim(dat, hess_calc=None)\n",
        "            except:\n",
        "                print(\"ERROR!!!\")\n",
        "                results += [[N, K, i, np.nan, np.nan]]\n",
        "                continue\n",
        "            \n",
        "            # Save all data, mainly duration and mean squared error in weight recovery\n",
        "            mse = np.average((rec['wMode'] - rec['input']['W'].T)**2)\n",
        "            print(\"      \" + str(rec['duration'].seconds) +\"s   mse =\", np.round(mse, 4))\n",
        "            results += [[N, K, i, rec['duration'], mse]]\n",
        "            \n",
        "# Update saved record of all info on each iteration\n",
        "np.savez(SPATH + \"FigS1_dat.npz\", results=results)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntObgps1gffY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats import sem\n",
        "res = np.load(SPATH + \"FigS1_dat.npz\", allow_pickle=True)['results']\n",
        "\n",
        "plt.figure(figsize=(2.5,2.5))\n",
        "COLORS = [colors['bias'],colors['s1'],colors['s2'],]\n",
        "adjust = [-0.3, 0, 0.3]\n",
        "for i, K in enumerate(num_weights):\n",
        "    all_duration = [i[3] for i in res if i[1]==K]\n",
        "    all_duration = np.array([i.total_seconds()/60\n",
        "                             if i is not None else np.nan\n",
        "                             for i in all_duration]).reshape(-1,num_simulations)\n",
        "    plt.errorbar(num_trials/1000 + adjust[i], np.nanmean(all_duration, axis=1),\n",
        "                 yerr=np.nanstd(all_duration, axis=1), #sem(all_duration, axis=1, nan_policy=\"omit\"),\n",
        "                 color=COLORS[i], marker=\"o\", markersize=3, lw=1)\n",
        "\n",
        "\n",
        "plt.xlim(0.25, 16.5)\n",
        "plt.ylim(0, 8.2)\n",
        "plt.xticks([1,2,4,8,16])\n",
        "# plt.gca().set_yticklabels([0,1,2,3])\n",
        "plt.gca().spines['right'].set_visible(False)\n",
        "plt.gca().spines['top'].set_visible(False)\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"FigS1a.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-07T16:16:42.028103Z",
          "start_time": "2020-04-07T16:16:41.976184Z"
        },
        "id": "T-GAuSxKgffZ",
        "colab_type": "text"
      },
      "source": [
        "## Figure S1b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70IYar3jgffa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats import sem\n",
        "\n",
        "plt.figure(figsize=(2.5,2.5))\n",
        "COLORS = [colors['bias'],colors['s1'],colors['s2']]\n",
        "adjust = [-0.3, 0, 0.3]\n",
        "for i, K in enumerate(num_weights):\n",
        "    all_mse = [i[4] for i in res if i[1]==K]\n",
        "    all_mse = np.array([i if i is not None else np.nan\n",
        "                        for i in all_mse]).reshape(-1,num_simulations)\n",
        "    plt.errorbar(num_trials/1000 + adjust[i], np.nanmean(all_mse, axis=1),\n",
        "                 yerr=np.nanstd(all_mse, axis=1),\n",
        "#                  yerr=sem(all_mse, axis=1, nan_policy=\"omit\"),\n",
        "                 color=COLORS[i], linestyle=\"None\", marker=\"o\", markersize=3, lw=1)\n",
        "\n",
        "plt.xlim(0.25, 16.5); plt.ylim(0, 0.152)\n",
        "plt.xticks([1,2,4,8,16]); plt.yticks([0,0.05,0.1,0.15])\n",
        "plt.gca().spines['right'].set_visible(False)\n",
        "plt.gca().spines['top'].set_visible(False)\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"FigS1b.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnYu3m2jgffc",
        "colab_type": "text"
      },
      "source": [
        "## Figure S2a"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T21:16:58.137158Z",
          "start_time": "2020-04-18T21:15:53.554577Z"
        },
        "id": "ZBl6Y6DRgffc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Collect data from manually determined training period\n",
        "outData = getMouse('CSHL_003', 5)\n",
        "\n",
        "prev_choice = np.hstack(([0], outData['y'][:-1]*2 - 3)).reshape(-1,1)\n",
        "prev_answer = np.hstack(([0], outData['answer'][:-1]*2 - 3)).reshape(-1,1)\n",
        "outData['inputs']['c'] = prev_choice\n",
        "outData['inputs']['h'] = prev_answer\n",
        "\n",
        "new_dat = psy.trim(outData, END=7000)\n",
        "\n",
        "# Compute\n",
        "weights = {'bias' : 0, 'cL' : 1, 'cR' : 1, 'h' : 1, 'c' : 1}\n",
        "K = np.sum([weights[i] for i in weights.keys()])\n",
        "hyper_guess = {\n",
        " 'sigma'   : [2**-5]*K,\n",
        " 'sigInit' : 2**5,\n",
        " 'sigDay'  : None\n",
        "  }\n",
        "optList = ['sigma']\n",
        "\n",
        "hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList)\n",
        "\n",
        "dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'W_std' : hess_info['W_std'],\n",
        "       'weights' : weights, 'new_dat' : new_dat}\n",
        "\n",
        "# Save interim result\n",
        "np.savez_compressed(SPATH+'figS2a_data.npz', dat=dat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T21:16:58.992824Z",
          "start_time": "2020-04-18T21:16:58.139960Z"
        },
        "id": "PxDgBeCJgffe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dat = np.load(SPATH+'figS2a_data.npz', allow_pickle=True)['dat'].item()\n",
        "\n",
        "fig = psy.plot_weights(dat['wMode'], dat['weights'], days=dat['new_dat'][\"dayLength\"], \n",
        "                       errorbar=dat['W_std'], figsize=(2.75,1.3))\n",
        "\n",
        "plt.axvline(np.cumsum(dat['new_dat']['dayLength'])[8], c=\"black\", lw=1.5, ls=\"--\", zorder=15)\n",
        "plt.ylim(-5.3,5.3)\n",
        "plt.xlim(0, 6950)\n",
        "plt.yticks([-4,-2,0,2,4])\n",
        "plt.xlabel(None); plt.ylabel(None)\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"FigS2a.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiDbAJF_gfff",
        "colab_type": "text"
      },
      "source": [
        "## Figure S2b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T21:18:02.691538Z",
          "start_time": "2020-04-18T21:16:58.995712Z"
        },
        "id": "wu-_q82Zgffg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Collect data from manually determined training period\n",
        "outData = getMouse('CSHL_003', 5)\n",
        "\n",
        "new_dat = psy.trim(outData, END=7000)\n",
        "\n",
        "# Compute\n",
        "weights = {'bias' : 1, 'cL' : 1, 'cR' : 1}\n",
        "K = np.sum([weights[i] for i in weights.keys()])\n",
        "hyper_guess = {\n",
        " 'sigma'   : [2**-5]*K,\n",
        " 'sigInit' : 2**5,\n",
        " 'sigDay'  : None\n",
        "  }\n",
        "optList = ['sigma']\n",
        "\n",
        "hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList)\n",
        "\n",
        "dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'W_std' : hess_info['W_std'],\n",
        "       'weights' : weights, 'new_dat' : new_dat}\n",
        "\n",
        "# Save interim result\n",
        "np.savez_compressed(SPATH+'figS2b_data.npz', dat=dat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T21:18:03.502254Z",
          "start_time": "2020-04-18T21:18:02.693872Z"
        },
        "id": "Ke-_V1aTgffh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dat = np.load(SPATH+'figS2b_data.npz', allow_pickle=True)['dat'].item()\n",
        "\n",
        "fig = psy.plot_weights(dat['wMode'], dat['weights'], days=dat['new_dat'][\"dayLength\"], \n",
        "                       errorbar=dat['W_std'], figsize=(2.75,1.3))\n",
        "\n",
        "plt.axvline(np.cumsum(dat['new_dat']['dayLength'])[8], c=\"black\", lw=1.5, ls=\"--\", zorder=15)\n",
        "plt.ylim(-5.3,5.3)\n",
        "plt.xlim(0, 6950)\n",
        "plt.yticks([-4,-2,0,2,4])\n",
        "plt.xlabel(None); plt.ylabel(None)\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"FigS2b.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMs8J6nXgffj",
        "colab_type": "text"
      },
      "source": [
        "## Figure S3a"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T21:18:46.285063Z",
          "start_time": "2020-04-18T21:18:45.500800Z"
        },
        "id": "4R4_pYK3gffk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contrasts = [-1, -0.5, -0.25, -0.125, -0.0625, 0, 0.0625, 0.125, 0.25, 0.5, 1.0]\n",
        "def tanh_transform(c, p):\n",
        "    return np.tanh(p*np.array(c))/np.tanh(p)\n",
        "\n",
        "\n",
        "COLORS = [colors['s_avg'], colors['c'], colors['h']]\n",
        "plt.figure(figsize=(2.25, 2.25))\n",
        "plt.plot(contrasts, contrasts, \"ko-\", markersize=3, lw=1, label=\"Original\")\n",
        "for i, j in enumerate([1,3,5]):\n",
        "    plt.plot(contrasts, tanh_transform(contrasts, j),\n",
        "             \"o-\", markersize=3, lw=1, color=COLORS[i], label=r\"$p = $\" +str(j))\n",
        "\n",
        "plt.axhline(0, color=\"black\", linestyle=\"--\", lw=0.5, zorder=0)#, alpha=0.5)\n",
        "plt.axvline(0, color=\"black\", linestyle=\"--\", lw=0.5, zorder=0)#, alpha=0.5)\n",
        "plt.legend(fontsize=10)\n",
        "\n",
        "# plt.xlabel(\"Original Contrasts\"); plt.ylabel(\"Transformed Contrasts\")\n",
        "plt.xlim(-1.05,1.05); plt.ylim(-1.05,1.05)\n",
        "plt.xticks(contrasts, va=\"top\", ha=\"center\")\n",
        "plt.yticks(contrasts, rotation=90, va=\"center\", ha=\"right\", ma=\"center\")\n",
        "plt.gca().set_xticklabels([\"100%\\nLeft\",None,None,None,None,0,None,None,None,None,\"100%\\nRight\"])\n",
        "plt.gca().set_yticklabels([\"100%\\nLeft\",None,None,None,None,0,None,None,None,None,\"100%\\nRight\"])\n",
        "\n",
        "plt.gca().spines['right'].set_visible(False)\n",
        "plt.gca().spines['top'].set_visible(False)\n",
        "\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"FigS3a.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXDOmRvsgffl",
        "colab_type": "text"
      },
      "source": [
        "## Figure S3b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T21:20:14.311129Z",
          "start_time": "2020-04-18T21:18:48.752204Z"
        },
        "id": "E9yv_dgrgffm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Collect data from manually determined training period\n",
        "outData = getMouse(\"CSHL_003\", 0.00001)\n",
        "_start  = np.where(outData['date'] >= '2019-03-21')[0][0]\n",
        "_end    = np.where(outData['date'] >= '2019-03-23')[0][0]\n",
        "new_dat = psy.trim(outData, START=_start, END=_end)\n",
        "\n",
        "# Hardcode random trials where probL != 0.5 before bias blocks begin to 0.5\n",
        "new_dat['probL'][:np.where(new_dat['date'] >= '2019-03-22')[0][0]] = 0.5\n",
        "\n",
        "# Compute\n",
        "weights = {'bias' : 1, 'cL' : 1, 'cR' : 1}\n",
        "K = np.sum([weights[i] for i in weights.keys()])\n",
        "hyper_guess = {\n",
        " 'sigma'   : [2**-5]*K,\n",
        " 'sigInit' : 2**5,\n",
        " 'sigDay'  : [2**-5]*K\n",
        "  }\n",
        "optList = ['sigma', 'sigDay']\n",
        "\n",
        "hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList)\n",
        "\n",
        "dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'W_std' : hess_info['W_std'],\n",
        "       'weights' : weights, 'new_dat' : new_dat}\n",
        "\n",
        "# Save interim result\n",
        "np.savez_compressed(SPATH+'figS3b_data.npz', dat=dat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T21:20:15.141426Z",
          "start_time": "2020-04-18T21:20:14.314075Z"
        },
        "id": "S35DlIJtgffo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dat = np.load(SPATH+'figS3b_data.npz', allow_pickle=True)['dat'].item()\n",
        "\n",
        "fig = psy.plot_weights(dat['wMode'], dat['weights'], days=dat['new_dat'][\"dayLength\"], \n",
        "                       errorbar=dat['W_std'], figsize=(3,1.5))\n",
        "fig = addBiasBlocks(fig, dat['new_dat']['probL'])\n",
        "\n",
        "plt.xlabel(None); plt.ylabel(None)\n",
        "plt.gca().set_yticks(np.arange(-15,16,5))\n",
        "plt.ylim(-16.3,16.3)\n",
        "\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"FigS3b.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SiTnMhvgffq",
        "colab_type": "text"
      },
      "source": [
        "## Figure S4a"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T21:21:44.230480Z",
          "start_time": "2020-04-18T21:20:15.144756Z"
        },
        "id": "rcsbxcfLgffq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_dat = getHuman(6)\n",
        "\n",
        "prev_choice = np.hstack(([0], new_dat['y'][:-1]*2 - 1)).reshape(-1,1)\n",
        "prev_answer = np.hstack(([0], new_dat['answer'][:-1]*2 - 1)).reshape(-1,1)\n",
        "new_dat['inputs']['c'] = prev_choice\n",
        "new_dat['inputs']['h'] = prev_answer\n",
        "\n",
        "# Compute\n",
        "weights = {'bias': 1, 's_a': 1, 's_b': 1, 's_avg': 1, 'h': 1, 'c': 1}\n",
        "K = np.sum([weights[i] for i in weights.keys()])\n",
        "hyper_guess = {\n",
        " 'sigma'   : [2**-5]*K,\n",
        " 'sigInit' : 2**5,\n",
        " 'sigDay'  : None\n",
        "  }\n",
        "optList = ['sigma']\n",
        "\n",
        "hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList)\n",
        "\n",
        "dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'W_std' : hess_info['W_std'],\n",
        "       'weights' : weights, 'new_dat' : new_dat}\n",
        "\n",
        "# Save interim result\n",
        "np.savez_compressed(SPATH+'figS4a_data.npz', dat=dat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T21:21:44.879328Z",
          "start_time": "2020-04-18T21:21:44.233177Z"
        },
        "id": "-P8uPFDNgffu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dat = np.load(SPATH+'figS4a_data.npz', allow_pickle=True)['dat'].item()\n",
        "fig = psy.plot_weights(dat['wMode'], dat['weights'], errorbar=dat['W_std'], figsize=(4.75,1.4))\n",
        "\n",
        "plt.xlabel(None); plt.ylabel(None)\n",
        "plt.gca().set_xticks([0,500,1000,1500,2000])\n",
        "plt.gca().set_yticks(np.arange(-2, 3,2))\n",
        "plt.xlim(0, 1900); plt.ylim(-3.4, 3.4)\n",
        "\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"FigS4a.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEztwr3ygffx",
        "colab_type": "text"
      },
      "source": [
        "## Figure S4b\n",
        "\n",
        "_6 min_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T21:28:26.762371Z",
          "start_time": "2020-04-18T21:22:50.545819Z"
        },
        "id": "UVlNuhLngffx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_dat = []\n",
        "all_subjects = HUMAN_DF[\"subject_id\"].unique()\n",
        "for i, subject in enumerate(all_subjects):\n",
        "    \n",
        "    print(\"\\rProcessing \" + str(i+1) + \" of \" + str(len(all_subjects)), end=\"\")\n",
        "    new_dat = getHuman(subject)\n",
        "\n",
        "    prev_choice = np.hstack(([0], new_dat['y'][:-1]*2 - 1)).reshape(-1,1)\n",
        "    prev_answer = np.hstack(([0], new_dat['answer'][:-1]*2 - 1)).reshape(-1,1)\n",
        "    new_dat['inputs']['c'] = prev_choice\n",
        "    new_dat['inputs']['h'] = prev_answer\n",
        "\n",
        "    # Compute\n",
        "    weights = {'bias': 1, 's_a': 1, 's_b': 1, 's_avg': 1, 'h': 1, 'c': 1}\n",
        "    K = np.sum([weights[i] for i in weights.keys()])\n",
        "    hyper_guess = {\n",
        "     'sigma'   : [2**-5]*K,\n",
        "     'sigInit' : 2**5,\n",
        "     'sigDay'  : None\n",
        "      }\n",
        "    optList = ['sigma']\n",
        "\n",
        "    hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList)\n",
        "\n",
        "    dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'W_std' : hess_info['W_std'],\n",
        "           'weights' : weights, 'new_dat' : new_dat}\n",
        "    all_dat += [dat]\n",
        "\n",
        "# Save interim result\n",
        "np.savez_compressed(SPATH+'figS4b_data.npz', all_dat=all_dat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-18T21:28:27.435087Z",
          "start_time": "2020-04-18T21:28:26.764779Z"
        },
        "id": "2GUTq4xegff2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_dat = np.load(SPATH+'figS4b_data.npz', allow_pickle=True)['all_dat']\n",
        "\n",
        "plt.figure(figsize=(4.75,1.4))\n",
        "for dat in all_dat:\n",
        "\n",
        "    weights = dat['weights']\n",
        "    wMode = dat['wMode']\n",
        "    labels = []\n",
        "    for j in sorted(weights.keys()):\n",
        "        labels += [j]*weights[j]\n",
        "\n",
        "    for i, w in enumerate(labels):\n",
        "        if w in ['h', 'c']:\n",
        "            plt.plot(wMode[i], lw=1.5, alpha=0.5, linestyle='-', c=colors[w], zorder=zorder[w])\n",
        "\n",
        "plt.axhline(0, color=\"black\", linestyle=\"--\", lw=1, alpha=0.5, zorder=0)\n",
        "plt.gca().set_xticks([0,500,1000,1500,2000])\n",
        "plt.gca().set_yticks(np.arange(-2, 3,2))\n",
        "plt.xlim(0, 1900); plt.ylim(-3.4, 3.4)\n",
        "\n",
        "plt.gca().spines['right'].set_visible(False)\n",
        "plt.gca().spines['top'].set_visible(False)\n",
        "plt.subplots_adjust(0,0,1,1) \n",
        "plt.savefig(SPATH + \"FigS4b.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYk-P-xegff3",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "N2E8Peqygff4",
        "colab_type": "text"
      },
      "source": [
        "# Notebook Versioning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "_DozFiOsgff4",
        "colab_type": "text"
      },
      "source": [
        "**1.0.0** : (May 21, 2020) original release"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hy2T21cAgff5",
        "colab_type": "text"
      },
      "source": [
        "# Download All Figures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtB9zwi3h_Q9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r \"all_figures.zip\" . -i \"{SPATH}*.pdf\"\n",
        "import time; time.sleep(10)\n",
        "files.download(\"all_figures.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}